==1860== NVPROF is profiling process 1860, command: python tf_cnn_benchmarks.py --num_gpus=1 --batch_size=16 --num_batches=10 --num_warmup_batches=0 --model=alexnet --data_dir=/home/keshavsanthanam/data/imagenet --allow_growth
2019-01-28 04:11:16.341116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-28 04:11:16.341716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:04.0
totalMemory: 15.75GiB freeMemory: 15.31GiB
2019-01-28 04:11:16.341745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-01-28 04:11:17.216651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-28 04:11:17.216700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-01-28 04:11:17.216708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-01-28 04:11:17.217026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14809 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
W0128 04:11:17.647913 139755831890304 tf_logging.py:125] From /home/keshavsanthanam/gpusched/workloads/tensorflow/image_classification/benchmark_cnn.py:2250: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2019-01-28 04:11:17.708237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-01-28 04:11:17.708330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-28 04:11:17.708336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-01-28 04:11:17.708343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-01-28 04:11:17.708691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14809 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
I0128 04:11:17.909101 139755831890304 tf_logging.py:115] Running local_init_op.
I0128 04:11:48.463100 139755831890304 tf_logging.py:115] Done running local_init_op.
TensorFlow:  1.12
Model:       alexnet
Dataset:     imagenet
Mode:        training
SingleSess:  False
Batch size:  16 global
             16 per device
Num batches: 10
Num epochs:  0.00
Devices:     ['/gpu:0']
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
==========
start:2019-01-28 04:11:17.219697
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 2.3 +/- 0.0 (jitter = 0.0)	7.223
10	images/sec: 9.0 +/- 1.1 (jitter = 0.9)	7.278
----------------------------------------------------------------
total images/sec: 8.99
----------------------------------------------------------------
end:2019-01-28 04:12:06.369064
==1860== Profiling application: python tf_cnn_benchmarks.py --num_gpus=1 --batch_size=16 --num_batches=10 --num_warmup_batches=0 --model=alexnet --data_dir=/home/keshavsanthanam/data/imagenet --allow_growth
==1860== Profiling result:
==1860== Metric result:
"Device","Kernel","Invocations","Metric Name","Metric Description","Min","Max","Avg"
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)",12,"l2_read_throughput","L2 Throughput (Reads)",392.788388GB/s,468.268991GB/s,434.763113GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",188,"l2_read_throughput","L2 Throughput (Reads)",139.562095MB/s,414.300156GB/s,349.258517GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",702.091521MB/s,752.900776MB/s,725.687305MB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const , float const >, Eigen::TensorBroadcastingOp<Eigen::array<long, unsigned long=1> const , Eigen::TensorReshapingOp<Eigen::Sizes<> const , Eigen::TensorMap<Eigen::TensorFixedSize<float const , Eigen::Sizes<>, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",160,"l2_read_throughput","L2 Throughput (Reads)",293.989826MB/s,513.904183GB/s,479.660824GB/s
"Tesla V100-SXM2-16GB (0)","void flip_filter<float, float>(float*, float const *, int, int, int, int)",16,"l2_read_throughput","L2 Throughput (Reads)",34.877875GB/s,176.396931GB/s,55.700836GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::MaxReducer<float>, int>(Eigen::internal::MaxReducer<float>, float, long=1, float, Eigen::internal::MaxReducer<float>::CoeffReturnType*)",10,"l2_read_throughput","L2 Throughput (Reads)",2.125209GB/s,2.178108GB/s,2.146894GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)",6,"l2_read_throughput","L2 Throughput (Reads)",137.634810GB/s,148.312730GB/s,144.871505GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",6,"l2_read_throughput","L2 Throughput (Reads)",160.164768GB/s,192.686997GB/s,176.619103GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",40,"l2_read_throughput","L2 Throughput (Reads)",86.267678GB/s,103.704027GB/s,94.705326GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorReshapingOp<Eigen::IndexList<int> const , Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>> const > const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",15.560848GB/s,16.038175GB/s,15.901596GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeBOffsetsKernel(cudnn::gemm::ComputeBOffsetsParams)",8,"l2_read_throughput","L2 Throughput (Reads)",138.716264MB/s,492.219002MB/s,324.309885MB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",12,"l2_read_throughput","L2 Throughput (Reads)",500.814334GB/s,546.833381GB/s,533.525288GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeWgradBOffsetsKernel(cudnn::gemm::ComputeBOffsetsParams)",20,"l2_read_throughput","L2 Throughput (Reads)",135.033531MB/s,532.283339MB/s,261.616359MB/s
"Tesla V100-SXM2-16GB (0)","void scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)",38,"l2_read_throughput","L2 Throughput (Reads)",241.563943MB/s,1.246711GB/s,727.055618MB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x128_nn",10,"l2_read_throughput","L2 Throughput (Reads)",98.612369GB/s,98.791618GB/s,98.720419GB/s
"Tesla V100-SXM2-16GB (0)","void cub::DeviceReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int, cub::Sum>(int, cub::Sum, cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, cub::GridEvenShare<cub::Sum>, float)",60,"l2_read_throughput","L2 Throughput (Reads)",224.618808GB/s,788.135812GB/s,701.790505GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",2,"l2_read_throughput","L2 Throughput (Reads)",354.594151GB/s,354.675996GB/s,354.634909GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x32_nt",20,"l2_read_throughput","L2 Throughput (Reads)",347.131182GB/s,378.225453GB/s,366.671960GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::ColumnReduceKernel<float const *, float*, cub::Sum>(float const *, float*, int, int, cub::Sum, std::iterator_traits<tensorflow::functor::ColumnReduceKernel<float const *, float*, cub::Sum>>::value_type)",6,"l2_read_throughput","L2 Throughput (Reads)",2.211140GB/s,60.303137GB/s,16.034321GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)",4,"l2_read_throughput","L2 Throughput (Reads)",54.736174GB/s,56.222173GB/s,55.552374GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=1, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",18,"l2_read_throughput","L2 Throughput (Reads)",5.426983GB/s,68.234669GB/s,13.987079GB/s
"Tesla V100-SXM2-16GB (0)","void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const *, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(int, cub::Sum, cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, cub::Sum, int, float*, int)",1,"l2_read_throughput","L2 Throughput (Reads)",574.091953GB/s,574.091953GB/s,574.091953GB/s
"Tesla V100-SXM2-16GB (0)","void pooling_bw_kernel_max_nchw_fully_packed_small<float, float, int=3, cudnnNanPropagation_t=0>(cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor)",30,"l2_read_throughput","L2 Throughput (Reads)",147.783959GB/s,287.395671GB/s,233.496288GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_small_nn_v1",4,"l2_read_throughput","L2 Throughput (Reads)",175.825578GB/s,179.153651GB/s,177.784882GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const *, tensorflow::BiasGradNCHW_SharedAtomics<float>*, int, int, int, int)",50,"l2_read_throughput","L2 Throughput (Reads)",199.970772GB/s,394.879765GB/s,298.011105GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",18,"l2_read_throughput","L2 Throughput (Reads)",252.211389MB/s,3.670507GB/s,1.139613GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=5, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",6,"l2_read_throughput","L2 Throughput (Reads)",12.760051GB/s,16.464070GB/s,14.252325GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasNHWCKernel<float>(int, float const *, float const , tensorflow::BiasNHWCKernel<float>*, int)",30,"l2_read_throughput","L2 Throughput (Reads)",27.474016GB/s,111.218812GB/s,82.130239GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_relu_small_nn_v1",6,"l2_read_throughput","L2 Throughput (Reads)",118.711965GB/s,178.885971GB/s,153.928767GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",160,"l2_read_throughput","L2 Throughput (Reads)",240.295890MB/s,519.877975GB/s,486.468357GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_sum_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",499.543689MB/s,555.684247MB/s,538.233871MB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, int=1024, int=1024, int=2, bool=0>(unsigned int const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, int=1024, int=1024, int=2, bool=0>*)",10,"l2_read_throughput","L2 Throughput (Reads)",396.089577GB/s,433.164757GB/s,424.017177GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)",2,"l2_read_throughput","L2 Throughput (Reads)",173.799435GB/s,174.274644GB/s,174.035966GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",24,"l2_read_throughput","L2 Throughput (Reads)",463.243824GB/s,621.612521GB/s,530.115563GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)",2,"l2_read_throughput","L2 Throughput (Reads)",256.392910GB/s,262.581704GB/s,259.447836GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x32_sliced1x4_tn",20,"l2_read_throughput","L2 Throughput (Reads)",534.778524GB/s,623.919367GB/s,594.113139GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",70,"l2_read_throughput","L2 Throughput (Reads)",56.341617GB/s,519.174363GB/s,340.663542GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",24,"l2_read_throughput","L2 Throughput (Reads)",235.525468GB/s,434.932027GB/s,373.178936GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",40,"l2_read_throughput","L2 Throughput (Reads)",35.675528GB/s,59.035898GB/s,54.637022GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const *, tensorflow::BiasGradNHWC_SharedAtomics<float>*, int)",30,"l2_read_throughput","L2 Throughput (Reads)",28.692390GB/s,210.089998GB/s,157.051885GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_64x32_sliced1x4_nn",20,"l2_read_throughput","L2 Throughput (Reads)",637.401063GB/s,790.033047GB/s,746.301694GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_32x32<float, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*)",8,"l2_read_throughput","L2 Throughput (Reads)",197.738851GB/s,271.590041GB/s,249.512340GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_small_nn_v1",4,"l2_read_throughput","L2 Throughput (Reads)",126.332580GB/s,177.020471GB/s,141.151488GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",8,"l2_read_throughput","L2 Throughput (Reads)",472.908335GB/s,1080.539577GB/s,949.938574GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_relu_small_nn_v1",2,"l2_read_throughput","L2 Throughput (Reads)",181.278450GB/s,182.254283GB/s,181.765069GB/s
"Tesla V100-SXM2-16GB (0)","volta_cgemm_32x32_tn",8,"l2_read_throughput","L2 Throughput (Reads)",392.898880GB/s,448.376501GB/s,435.293047GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorBroadcastingOp<Eigen::array<int, unsigned long=1> const , Eigen::TensorReshapingOp<Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorMap<Eigen::TensorFixedSize<bool const , Eigen::Sizes<>, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",480.080948MB/s,486.702754MB/s,482.718044MB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_floor_op<float>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",20,"l2_read_throughput","L2 Throughput (Reads)",53.004130GB/s,66.541392GB/s,59.542154GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",12,"l2_read_throughput","L2 Throughput (Reads)",380.281251GB/s,420.163511GB/s,401.579023GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)",4,"l2_read_throughput","L2 Throughput (Reads)",295.101221GB/s,356.874506GB/s,332.973854GB/s
"Tesla V100-SXM2-16GB (0)","void im2col4d_kernel<float, int>(im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const *, float*, int)",10,"l2_read_throughput","L2 Throughput (Reads)",23.887850GB/s,117.120768GB/s,60.190775GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",24,"l2_read_throughput","L2 Throughput (Reads)",251.132239GB/s,260.411939GB/s,257.093605GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::BlockReduceKernel<cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int=256, cub::Sum>(float, float, int, float*, std::iterator_traits<tensorflow::functor::BlockReduceKernel<cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int=256, cub::Sum>>::value_type)",100,"l2_read_throughput","L2 Throughput (Reads)",172.091605MB/s,65.663359GB/s,18.171544GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",12,"l2_read_throughput","L2 Throughput (Reads)",124.057854GB/s,143.966861GB/s,136.656199GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",6,"l2_read_throughput","L2 Throughput (Reads)",132.390870GB/s,158.529139GB/s,146.455889GB/s
"Tesla V100-SXM2-16GB (0)","compute_gemm_pointers(float2**, float2 const *, int, float2 const *, int, float2 const *, int, int)",24,"l2_read_throughput","L2 Throughput (Reads)",663.425611MB/s,2.163072GB/s,1.443003GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)",6,"l2_read_throughput","L2 Throughput (Reads)",463.248189GB/s,507.446933GB/s,481.918467GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",24,"l2_read_throughput","L2 Throughput (Reads)",609.673591GB/s,648.047780GB/s,637.114409GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, int>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, int>(Eigen::internal::SumReducer<float>, float, long=1, float, Eigen::internal::SumReducer<float>::CoeffReturnType*)",10,"l2_read_throughput","L2 Throughput (Reads)",731.415956MB/s,765.534485MB/s,751.158243MB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::ShuffleInTensor3Simple<float, int=2, int=1, int=0, bool=0>(int, float const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::ShuffleInTensor3Simple<float, int=2, int=1, int=0, bool=0>*)",140,"l2_read_throughput","L2 Throughput (Reads)",39.460482GB/s,1130.879525GB/s,976.154764GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::RowReduceKernel<float const *, float*, cub::Sum>(float const *, float*, int, int, cub::Sum, std::iterator_traits<tensorflow::functor::RowReduceKernel<float const *, float*, cub::Sum>>::value_type)",3,"l2_read_throughput","L2 Throughput (Reads)",386.041993GB/s,597.938726GB/s,523.884609GB/s
"Tesla V100-SXM2-16GB (0)","volta_gcgemm_32x32_nt",16,"l2_read_throughput","L2 Throughput (Reads)",505.539554GB/s,673.617792GB/s,652.415608GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_nn",10,"l2_read_throughput","L2 Throughput (Reads)",322.250079GB/s,489.632966GB/s,440.673086GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_16x16<float>(float2*, float const *, int, int, int, int, int, int, int, int)",36,"l2_read_throughput","L2 Throughput (Reads)",20.025497GB/s,232.427069GB/s,53.234523GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<__int64, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<__int64, __int64, Eigen::internal::scalar_max_op<__int64, __int64>>, Eigen::TensorMap<Eigen::Tensor<__int64 const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(__int64, int=1)",1,"l2_read_throughput","L2 Throughput (Reads)",419.038714MB/s,419.038714MB/s,419.038488MB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_nt",14,"l2_read_throughput","L2 Throughput (Reads)",292.483853GB/s,496.323949GB/s,450.321901GB/s
"Tesla V100-SXM2-16GB (0)","void cub::DeviceReduceSingleTileKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float*, float*, int, cub::Sum, float>(int, cub::Sum, cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float*, float*)",60,"l2_read_throughput","L2 Throughput (Reads)",263.327982MB/s,2.483527GB/s,1.328956GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_sum_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",20,"l2_read_throughput","L2 Throughput (Reads)",49.732625GB/s,55.240733GB/s,52.358463GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::TruncatedNormalDistribution<tensorflow::random::SingleSampleAdapter<tensorflow::random::PhiloxRandom>, float>>(tensorflow::random::PhiloxRandom, tensorflow::random::PhiloxRandomResultElementType*, __int64, tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::TruncatedNormalDistribution<tensorflow::random::SingleSampleAdapter<tensorflow::random::PhiloxRandom>, float>>)",8,"l2_read_throughput","L2 Throughput (Reads)",1.016229GB/s,32.313751GB/s,31.827393GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeWgradSplitKOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",20,"l2_read_throughput","L2 Throughput (Reads)",704.251802MB/s,3.263028GB/s,1.348966GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_splitK_small_nn_v1",16,"l2_read_throughput","L2 Throughput (Reads)",416.241362GB/s,679.606978GB/s,582.513761GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, int=0, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, int=0, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",30,"l2_read_throughput","L2 Throughput (Reads)",252.769544GB/s,387.252106GB/s,358.061014GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, unsigned long=2> const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",13.024188GB/s,14.109537GB/s,13.832879GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)",12,"l2_read_throughput","L2 Throughput (Reads)",119.641537GB/s,135.283771GB/s,129.183018GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",12,"l2_read_throughput","L2 Throughput (Reads)",129.707835GB/s,202.690297GB/s,179.883878GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasNCHWKernel<float>(int, float const *, float const , tensorflow::BiasNCHWKernel<float>*, int, int)",50,"l2_read_throughput","L2 Throughput (Reads)",192.508118GB/s,331.409880GB/s,272.789987GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=1, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",6,"l2_read_throughput","L2 Throughput (Reads)",9.098397GB/s,9.454893GB/s,9.288051GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",42,"l2_read_throughput","L2 Throughput (Reads)",194.320271GB/s,272.343441GB/s,241.414650GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=5, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",2,"l2_read_throughput","L2 Throughput (Reads)",16.121537GB/s,16.125362GB/s,16.123499GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=2, int=2, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",42,"l2_read_throughput","L2 Throughput (Reads)",684.054394GB/s,928.827477GB/s,855.245714GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, int>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",18.267314GB/s,19.409021GB/s,18.595469GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>>(tensorflow::random::PhiloxRandom, tensorflow::random::PhiloxRandomResultElementType*, __int64, tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>>)",20,"l2_read_throughput","L2 Throughput (Reads)",306.196436MB/s,3.804552GB/s,1.942743GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_relu_interior_nn_v1",2,"l2_read_throughput","L2 Throughput (Reads)",267.825146GB/s,277.679414GB/s,272.706991GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_16x16<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",18,"l2_read_throughput","L2 Throughput (Reads)",168.629086GB/s,594.511260GB/s,497.062240GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1>*, kernel_grad_params, int, int, float, int, int, int)",18,"l2_read_throughput","L2 Throughput (Reads)",382.107335GB/s,660.103007GB/s,582.645361GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_splitK_interior_nn_v1",4,"l2_read_throughput","L2 Throughput (Reads)",163.356381GB/s,164.669599GB/s,164.197243GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_64x32_sliced1x4_tn",10,"l2_read_throughput","L2 Throughput (Reads)",423.573898GB/s,436.466190GB/s,430.555988GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",759.407326MB/s,809.368334MB/s,799.375938MB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",15.207517GB/s,16.511019GB/s,15.897817GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, int>(Eigen::internal::SumReducer<float>, float, long=1, float, Eigen::internal::SumReducer<float>::CoeffReturnType*)",10,"l2_read_throughput","L2 Throughput (Reads)",2.270596GB/s,2.285245GB/s,2.278393GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::BlockReduceKernel<float*, float*, int=256, tensorflow::functor::Sum<float>>(float*, float*, int, float, std::iterator_traits<tensorflow::functor::BlockReduceKernel<float*, float*, int=256, tensorflow::functor::Sum<float>>>::value_type)",10,"l2_read_throughput","L2 Throughput (Reads)",765.625859MB/s,782.150158MB/s,776.008866MB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>>::value_type)",20,"l2_read_throughput","L2 Throughput (Reads)",156.340052MB/s,620.997229MB/s,393.794360MB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_32x32<float, bool=0, unsigned int=1, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*)",14,"l2_read_throughput","L2 Throughput (Reads)",316.307741GB/s,521.266638GB/s,419.951775GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_32x128_nt",10,"l2_read_throughput","L2 Throughput (Reads)",218.794656GB/s,238.135537GB/s,228.238509GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const , float const , Eigen::internal::ComparisonName>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",70,"l2_read_throughput","L2 Throughput (Reads)",83.066048GB/s,729.887194GB/s,425.585630GB/s
"Tesla V100-SXM2-16GB (0)","volta_cgemm_32x64_tn",16,"l2_read_throughput","L2 Throughput (Reads)",248.722803GB/s,276.812360GB/s,265.998914GB/s
