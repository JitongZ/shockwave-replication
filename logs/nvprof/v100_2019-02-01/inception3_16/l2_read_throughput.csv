==29867== NVPROF is profiling process 29867, command: python tf_cnn_benchmarks.py --num_gpus=1 --batch_size=16 --num_batches=10 --num_warmup_batches=0 --model=inception3 --data_dir=/home/keshavsanthanam/data/imagenet --allow_growth
2019-01-28 03:32:59.200353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-28 03:32:59.200942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:04.0
totalMemory: 15.75GiB freeMemory: 15.31GiB
2019-01-28 03:32:59.200972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-01-28 03:33:00.137172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-28 03:33:00.137222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-01-28 03:33:00.137230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-01-28 03:33:00.137641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14809 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
W0128 03:33:05.272588 139904579838336 tf_logging.py:125] From /home/keshavsanthanam/gpusched/workloads/tensorflow/image_classification/benchmark_cnn.py:2250: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2019-01-28 03:33:06.125901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-01-28 03:33:06.125985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-01-28 03:33:06.125991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-01-28 03:33:06.125996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-01-28 03:33:06.126350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14809 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
I0128 03:33:08.641988 139904579838336 tf_logging.py:115] Running local_init_op.
I0128 03:33:39.519376 139904579838336 tf_logging.py:115] Done running local_init_op.
TensorFlow:  1.12
Model:       inception3
Dataset:     imagenet
Mode:        training
SingleSess:  False
Batch size:  16 global
             16 per device
Num batches: 10
Num epochs:  0.00
Devices:     ['/gpu:0']
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
==========
start:2019-01-28 03:33:00.140361
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 0.2 +/- 0.0 (jitter = 0.0)	7.384
10	images/sec: 0.7 +/- 0.1 (jitter = 0.0)	7.326
----------------------------------------------------------------
total images/sec: 0.72
----------------------------------------------------------------
end:2019-01-28 03:37:22.631815
==29867== Profiling application: python tf_cnn_benchmarks.py --num_gpus=1 --batch_size=16 --num_batches=10 --num_warmup_batches=0 --model=inception3 --data_dir=/home/keshavsanthanam/data/imagenet --allow_growth
==29867== Profiling result:
==29867== Metric result:
"Device","Kernel","Invocations","Metric Name","Metric Description","Min","Max","Avg"
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",2955,"l2_read_throughput","L2 Throughput (Reads)",147.549611MB/s,475.215788GB/s,76.369215GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const , float const >, Eigen::TensorBroadcastingOp<Eigen::array<long, unsigned long=1> const , Eigen::TensorReshapingOp<Eigen::Sizes<> const , Eigen::TensorMap<Eigen::TensorFixedSize<float const , Eigen::Sizes<>, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1900,"l2_read_throughput","L2 Throughput (Reads)",226.411887MB/s,455.031792GB/s,148.964825GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",90,"l2_read_throughput","L2 Throughput (Reads)",522.496662GB/s,611.165827GB/s,590.805870GB/s
"Tesla V100-SXM2-16GB (0)","void flip_filter<float, float>(float*, float const *, int, int, int, int)",136,"l2_read_throughput","L2 Throughput (Reads)",11.637670GB/s,145.297788GB/s,24.620918GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::MaxReducer<float>, int>(Eigen::internal::MaxReducer<float>, float, long=1, float, Eigen::internal::MaxReducer<float>::CoeffReturnType*)",10,"l2_read_throughput","L2 Throughput (Reads)",2.114183GB/s,2.171221GB/s,2.146547GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=4, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, int=4> const , Eigen::DSizes<int, int=4> const , Eigen::TensorMap<Eigen::Tensor<float const , int=4, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=4)",460,"l2_read_throughput","L2 Throughput (Reads)",103.704027GB/s,293.415234GB/s,235.668804GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)",12,"l2_read_throughput","L2 Throughput (Reads)",137.639673GB/s,295.040665GB/s,280.305489GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1880,"l2_read_throughput","L2 Throughput (Reads)",90.518240MB/s,1.015988GB/s,485.588078MB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",12,"l2_read_throughput","L2 Throughput (Reads)",127.411764GB/s,452.200488GB/s,431.041173GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",12,"l2_read_throughput","L2 Throughput (Reads)",153.237293GB/s,803.112082GB/s,510.525875GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",20,"l2_read_throughput","L2 Throughput (Reads)",562.408593GB/s,585.116986GB/s,576.521724GB/s
"Tesla V100-SXM2-16GB (0)","void fft1d_c2r_32<float2, float, float, bool=0, bool=1, bool=0, bool=1>(float*, float2 const *, int, int3, int3, int2, int, float, float, float*, float*)",24,"l2_read_throughput","L2 Throughput (Reads)",260.201468GB/s,441.459571GB/s,341.963846GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeBOffsetsKernel(cudnn::gemm::ComputeBOffsetsParams)",76,"l2_read_throughput","L2 Throughput (Reads)",206.199852MB/s,521.668002MB/s,367.111329MB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",212,"l2_read_throughput","L2 Throughput (Reads)",257.814850GB/s,661.120483GB/s,530.164602GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=1, int=2, int=128, int=8, int=8, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",12,"l2_read_throughput","L2 Throughput (Reads)",368.144469GB/s,386.726148GB/s,384.103609GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeWgradBOffsetsKernel(cudnn::gemm::ComputeBOffsetsParams)",172,"l2_read_throughput","L2 Throughput (Reads)",124.055195MB/s,600.739726MB/s,262.821600MB/s
"Tesla V100-SXM2-16GB (0)","void scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)",1104,"l2_read_throughput","L2 Throughput (Reads)",20.126041MB/s,2.721082GB/s,231.189136MB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x128_nn",4,"l2_read_throughput","L2 Throughput (Reads)",162.525296GB/s,185.801928GB/s,174.021276GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_splitK_interior_nn_v1",16,"l2_read_throughput","L2 Throughput (Reads)",314.387943GB/s,344.872729GB/s,331.821509GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x128_nt",8,"l2_read_throughput","L2 Throughput (Reads)",43.725055GB/s,199.219285GB/s,77.314913GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=6, int=5, int=4, int=4, bool=1, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=6, int=5, int=4, int=4, bool=1, bool=1>*, kernel_grad_params, int, int, float, int, int)",14,"l2_read_throughput","L2 Throughput (Reads)",318.780887GB/s,514.818240GB/s,427.521007GB/s
"Tesla V100-SXM2-16GB (0)","void pointwise_mult_and_sum_complex<float2, int=8, int=4>(float2*, float2*, float2*, int, int, int, int, int, float2)",72,"l2_read_throughput","L2 Throughput (Reads)",843.081368GB/s,1657.014552GB/s,1136.145283GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",90,"l2_read_throughput","L2 Throughput (Reads)",100.698256GB/s,446.817301GB/s,166.105489GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_relu_interior_nn_v1",6,"l2_read_throughput","L2 Throughput (Reads)",192.687042GB/s,299.747422GB/s,256.817462GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_small_nn_v1",14,"l2_read_throughput","L2 Throughput (Reads)",129.460131GB/s,169.835219GB/s,145.642833GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasNHWCKernel<float>(int, float const *, float const , tensorflow::BiasNHWCKernel<float>*, int)",10,"l2_read_throughput","L2 Throughput (Reads)",26.533563GB/s,28.588980GB/s,27.920461GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(cudnnTensorStruct, float const *, cudnn::detail::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::detail::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",940,"l2_read_throughput","L2 Throughput (Reads)",78.096447GB/s,261.544525GB/s,205.311421GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1000,"l2_read_throughput","L2 Throughput (Reads)",1.649365GB/s,517.472286GB/s,242.579077GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_sum_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",443.257076MB/s,484.173114MB/s,472.541193MB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, int=1024, int=1024, int=2, bool=0>(unsigned int const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, int=1024, int=1024, int=2, bool=0>*)",10,"l2_read_throughput","L2 Throughput (Reads)",449.876496GB/s,467.061743GB/s,461.374518GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)",2,"l2_read_throughput","L2 Throughput (Reads)",177.928430GB/s,196.151893GB/s,186.564205GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",472,"l2_read_throughput","L2 Throughput (Reads)",436.038336GB/s,802.276524GB/s,491.201769GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)",2,"l2_read_throughput","L2 Throughput (Reads)",172.273748GB/s,181.362524GB/s,176.673242GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1>*, kernel_grad_params, int, int, float, int, int, int)",484,"l2_read_throughput","L2 Throughput (Reads)",593.983961GB/s,893.164706GB/s,669.927235GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",940,"l2_read_throughput","L2 Throughput (Reads)",129.816896GB/s,487.942741GB/s,328.618067GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",308,"l2_read_throughput","L2 Throughput (Reads)",199.627429GB/s,632.963471GB/s,459.056474GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1880,"l2_read_throughput","L2 Throughput (Reads)",176.062950MB/s,1.088931GB/s,483.801476MB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_splitK_medium_nn_v1",12,"l2_read_throughput","L2 Throughput (Reads)",264.619282GB/s,354.613328GB/s,298.803987GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_32x32<float, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*)",284,"l2_read_throughput","L2 Throughput (Reads)",97.270880GB/s,343.199760GB/s,148.658930GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_small_nn_v1",24,"l2_read_throughput","L2 Throughput (Reads)",141.702635GB/s,237.867198GB/s,213.689139GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_relu_small_nn_v1",14,"l2_read_throughput","L2 Throughput (Reads)",117.654103GB/s,275.521725GB/s,206.677529GB/s
"Tesla V100-SXM2-16GB (0)","volta_cgemm_32x32_tn",918,"l2_read_throughput","L2 Throughput (Reads)",64.579588GB/s,462.556687GB/s,198.121639GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_clip<int=1, int=2, int=256, int=16, int=16, int=1, float, float, float2>(float*, float2*, int, int3, float2*, int, float2*, float2*, int, int, int, int, int, float, float, bool, int, float, float)",12,"l2_read_throughput","L2 Throughput (Reads)",288.060950GB/s,326.747475GB/s,310.183037GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorBroadcastingOp<Eigen::array<int, unsigned long=1> const , Eigen::TensorReshapingOp<Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorMap<Eigen::TensorFixedSize<bool const , Eigen::Sizes<>, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",449.502543MB/s,470.479329MB/s,462.160246MB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",684,"l2_read_throughput","L2 Throughput (Reads)",137.418609GB/s,756.468385GB/s,510.027175GB/s
"Tesla V100-SXM2-16GB (0)","void fft1d_r2c_32<float, float, float2, bool=0, bool=0>(float2*, float const *, int, int3, int3, int2, int2)",198,"l2_read_throughput","L2 Throughput (Reads)",2.334642GB/s,241.871665GB/s,85.628495GB/s
"Tesla V100-SXM2-16GB (0)","void fft1d_r2c_32<float, float, float2, bool=1, bool=0>(float2*, float const *, int, int3, int3, int2, int2)",62,"l2_read_throughput","L2 Throughput (Reads)",11.283538GB/s,88.025393GB/s,72.462761GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::BlockReduceKernel<cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int=256, cub::Sum>(float, float, int, float*, std::iterator_traits<tensorflow::functor::BlockReduceKernel<cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int=256, cub::Sum>>::value_type)",870,"l2_read_throughput","L2 Throughput (Reads)",703.902472MB/s,68.885542GB/s,49.892629GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",24,"l2_read_throughput","L2 Throughput (Reads)",100.818616GB/s,384.229803GB/s,356.744662GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, unsigned long=2> const , Eigen::array<int, unsigned long=2> const , Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>>, Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::GpuDevice>, int>(int, unsigned long=2)",460,"l2_read_throughput","L2 Throughput (Reads)",109.417098GB/s,310.124003GB/s,250.107141GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",6,"l2_read_throughput","L2 Throughput (Reads)",104.060574GB/s,111.529603GB/s,107.881133GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=1, int=4, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",16,"l2_read_throughput","L2 Throughput (Reads)",627.932550GB/s,1108.693186GB/s,1064.374245GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_bw_kernel_avg<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>(cudnnTensorStruct, float const *, float const , cudnn::detail::pooling_bw_kernel_avg<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>, float const , cudnn::detail::pooling_bw_kernel_avg<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",90,"l2_read_throughput","L2 Throughput (Reads)",2.690378GB/s,98.547721GB/s,75.928708GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_64x64<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",60,"l2_read_throughput","L2 Throughput (Reads)",230.741820GB/s,638.572265GB/s,511.120837GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::ShuffleInTensor3Simple<float, int=2, int=1, int=0, bool=0>(int, float const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::ShuffleInTensor3Simple<float, int=2, int=1, int=0, bool=0>*)",2810,"l2_read_throughput","L2 Throughput (Reads)",734.506927MB/s,1183.975347GB/s,617.102288GB/s
"Tesla V100-SXM2-16GB (0)","volta_gcgemm_32x32_nt",298,"l2_read_throughput","L2 Throughput (Reads)",308.010109GB/s,863.240062GB/s,683.411128GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_16x16<float>(float2*, float const *, int, int, int, int, int, int, int, int)",132,"l2_read_throughput","L2 Throughput (Reads)",2.606410GB/s,119.429055GB/s,20.133867GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::TruncatedNormalDistribution<tensorflow::random::SingleSampleAdapter<tensorflow::random::PhiloxRandom>, float>>(tensorflow::random::PhiloxRandom, tensorflow::random::PhiloxRandomResultElementType*, __int64, tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::TruncatedNormalDistribution<tensorflow::random::SingleSampleAdapter<tensorflow::random::PhiloxRandom>, float>>)",95,"l2_read_throughput","L2 Throughput (Reads)",389.644077MB/s,36.046687GB/s,16.662493GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_clip<int=1, int=2, int=128, int=16, int=32, int=1, float, float, float2>(float*, float2*, int, int3, float2*, int, float2*, float2*, int, int, int, int, int, float, float, bool, int, float, float)",12,"l2_read_throughput","L2 Throughput (Reads)",278.333788GB/s,341.653290GB/s,326.802902GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeWgradSplitKOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",172,"l2_read_throughput","L2 Throughput (Reads)",704.251802MB/s,3.519959GB/s,1.471246GB/s
"Tesla V100-SXM2-16GB (0)","volta_cgemm_64x32_tn",292,"l2_read_throughput","L2 Throughput (Reads)",180.131164GB/s,413.451318GB/s,321.773730GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_splitK_small_nn_v1",52,"l2_read_throughput","L2 Throughput (Reads)",229.637799GB/s,776.630980GB/s,473.756380GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, int=0, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, int=0, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",50,"l2_read_throughput","L2 Throughput (Reads)",134.373762GB/s,666.400396GB/s,489.645931GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, unsigned long=2> const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",14.063962GB/s,14.527609GB/s,14.400734GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",388,"l2_read_throughput","L2 Throughput (Reads)",19.517113GB/s,272.866129GB/s,130.374818GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=1, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",12,"l2_read_throughput","L2 Throughput (Reads)",3.670507GB/s,9.625602GB/s,9.280556GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",124,"l2_read_throughput","L2 Throughput (Reads)",7.888850GB/s,269.718392GB/s,69.566464GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=4, int=6, int=3, int=2, int=4, bool=1, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=4, int=6, int=3, int=2, int=4, bool=1, bool=1>*, kernel_grad_params, int, int, float, int, int)",24,"l2_read_throughput","L2 Throughput (Reads)",1006.738812GB/s,1119.676998GB/s,1072.221771GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=5, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",2,"l2_read_throughput","L2 Throughput (Reads)",12.725809GB/s,12.915452GB/s,12.810953GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, int>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",17.916020GB/s,19.275166GB/s,18.645090GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_relu_interior_nn_v1",42,"l2_read_throughput","L2 Throughput (Reads)",100.766102GB/s,410.044130GB/s,270.002249GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1>*, kernel_grad_params, int, int, float, int, int, int)",194,"l2_read_throughput","L2 Throughput (Reads)",584.660712GB/s,773.785765GB/s,699.205435GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_32x128_nn",10,"l2_read_throughput","L2 Throughput (Reads)",174.765680GB/s,219.796918GB/s,187.828015GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",15.410284GB/s,16.052379GB/s,15.682107GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::BlockReduceKernel<float*, float*, int=256, tensorflow::functor::Sum<float>>(float*, float*, int, float, std::iterator_traits<tensorflow::functor::BlockReduceKernel<float*, float*, int=256, tensorflow::functor::Sum<float>>>::value_type)",10,"l2_read_throughput","L2 Throughput (Reads)",744.649808MB/s,787.817913MB/s,776.008866MB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>>::value_type)",850,"l2_read_throughput","L2 Throughput (Reads)",142.339450MB/s,566.244125MB/s,170.422623MB/s
"Tesla V100-SXM2-16GB (0)","void pooling_bw_kernel_max_nchw_fully_packed_large<float, float, int=3, cudnnNanPropagation_t=0>(cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, int)",10,"l2_read_throughput","L2 Throughput (Reads)",178.133380GB/s,181.567763GB/s,180.109164GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_32x128_nt",10,"l2_read_throughput","L2 Throughput (Reads)",204.986299GB/s,220.740913GB/s,211.993607GB/s
"Tesla V100-SXM2-16GB (0)","volta_cgemm_32x64_tn",82,"l2_read_throughput","L2 Throughput (Reads)",238.669832GB/s,284.128379GB/s,277.198348GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)",24,"l2_read_throughput","L2 Throughput (Reads)",235.974119GB/s,390.880161GB/s,372.618755GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",715.255737MB/s,752.900776MB/s,738.804977MB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=1, int=2, int=256, int=16, int=16, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",12,"l2_read_throughput","L2 Throughput (Reads)",366.555205GB/s,377.405580GB/s,373.761125GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_tn",10,"l2_read_throughput","L2 Throughput (Reads)",167.725811GB/s,171.488586GB/s,169.588138GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x32_relu_interior_nn_v1",4,"l2_read_throughput","L2 Throughput (Reads)",185.527286GB/s,279.885165GB/s,260.050377GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorReshapingOp<Eigen::IndexList<int> const , Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>> const > const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",15.516499GB/s,16.038175GB/s,15.753844GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_interior_nn_v1",14,"l2_read_throughput","L2 Throughput (Reads)",182.574424GB/s,467.989463GB/s,326.261967GB/s
"Tesla V100-SXM2-16GB (0)","void cub::DeviceReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int, cub::Sum>(int, cub::Sum, cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, cub::GridEvenShare<cub::Sum>, float)",90,"l2_read_throughput","L2 Throughput (Reads)",242.629777GB/s,418.467775GB/s,346.197030GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",2,"l2_read_throughput","L2 Throughput (Reads)",477.589507GB/s,477.890934GB/s,477.740198GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_pad<int=0, int=1, int=256, int=16, int=16, int=1, float, float, float2>(float2*, float*, int, int3, float*, int, float*, float*, int, int, int, int, int, bool)",24,"l2_read_throughput","L2 Throughput (Reads)",260.556273MB/s,197.385220GB/s,92.998785GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::ColumnReduceKernel<float const *, float*, cub::Sum>(float const *, float*, int, int, cub::Sum, std::iterator_traits<tensorflow::functor::ColumnReduceKernel<float const *, float*, cub::Sum>>::value_type)",1,"l2_read_throughput","L2 Throughput (Reads)",19.748973GB/s,19.748973GB/s,19.748973GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)",4,"l2_read_throughput","L2 Throughput (Reads)",32.502488GB/s,35.724579GB/s,34.250937GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=1, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",68,"l2_read_throughput","L2 Throughput (Reads)",657.625410MB/s,27.697246GB/s,4.897464GB/s
"Tesla V100-SXM2-16GB (0)","void pooling_bw_kernel_max_nchw_fully_packed_small<float, float, int=3, cudnnNanPropagation_t=0>(cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor)",30,"l2_read_throughput","L2 Throughput (Reads)",118.843817GB/s,325.086708GB/s,206.805398GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",162,"l2_read_throughput","L2 Throughput (Reads)",120.147944MB/s,3.615723GB/s,1.266770GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=5, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",2,"l2_read_throughput","L2 Throughput (Reads)",10.146184GB/s,10.342139GB/s,10.254808GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_relu_small_nn_v1",20,"l2_read_throughput","L2 Throughput (Reads)",130.118776GB/s,171.867005GB/s,151.197730GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(float, float, float, float, cudnnTensorStruct, float const *, cudnn::detail::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, float const , cudnn::detail::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::detail::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",940,"l2_read_throughput","L2 Throughput (Reads)",144.833716GB/s,400.638509GB/s,310.558526GB/s
"Tesla V100-SXM2-16GB (0)","volta_gcgemm_64x64_nt",150,"l2_read_throughput","L2 Throughput (Reads)",113.690986GB/s,152.744624GB/s,137.380205GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_64x64<float>(float2*, float const *, int, int, int, int, int, int, int, int)",120,"l2_read_throughput","L2 Throughput (Reads)",1.028397GB/s,151.710054GB/s,43.389761GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const *, tensorflow::BiasGradNHWC_SharedAtomics<float>*, int)",10,"l2_read_throughput","L2 Throughput (Reads)",28.692390GB/s,29.090895GB/s,28.910206GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",12,"l2_read_throughput","L2 Throughput (Reads)",372.996663GB/s,375.005702GB/s,374.493331GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>, float const , cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>, float const , cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",10,"l2_read_throughput","L2 Throughput (Reads)",600.835563GB/s,621.352562GB/s,611.790490GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_pad<int=0, int=1, int=128, int=16, int=32, int=1, float, float, float2>(float2*, float*, int, int3, float*, int, float*, float*, int, int, int, int, int, bool)",24,"l2_read_throughput","L2 Throughput (Reads)",400.463655MB/s,179.523183GB/s,49.458756GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",64,"l2_read_throughput","L2 Throughput (Reads)",381.422589GB/s,898.433442GB/s,646.447089GB/s
"Tesla V100-SXM2-16GB (0)","void fft1d_r2c_32<float, float, float2, bool=0, bool=1>(float2*, float const *, int, int3, int3, int2, int2)",24,"l2_read_throughput","L2 Throughput (Reads)",77.543907GB/s,189.452793GB/s,154.256565GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)",4,"l2_read_throughput","L2 Throughput (Reads)",637.508864GB/s,721.005731GB/s,688.415308GB/s
"Tesla V100-SXM2-16GB (0)","void im2col4d_kernel<float, int>(im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const *, float*, int)",86,"l2_read_throughput","L2 Throughput (Reads)",14.411822GB/s,273.971231GB/s,75.016967GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=0, int=1, int=256, int=16, int=16, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",24,"l2_read_throughput","L2 Throughput (Reads)",361.813336GB/s,374.271239GB/s,370.889016GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",22,"l2_read_throughput","L2 Throughput (Reads)",275.821404GB/s,281.055077GB/s,278.356700GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=4, int=1, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",96,"l2_read_throughput","L2 Throughput (Reads)",433.077613GB/s,935.530285GB/s,758.595731GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_interior_nn_v1",24,"l2_read_throughput","L2 Throughput (Reads)",163.517260GB/s,343.199219GB/s,279.244295GB/s
"Tesla V100-SXM2-16GB (0)","compute_gemm_pointers(float2**, float2 const *, int, float2 const *, int, float2 const *, int, int)",140,"l2_read_throughput","L2 Throughput (Reads)",412.399704MB/s,2.163072GB/s,1.330050GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1>*, kernel_grad_params, int, int, float, int, int, int)",206,"l2_read_throughput","L2 Throughput (Reads)",584.348949GB/s,974.882373GB/s,837.542754GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",342,"l2_read_throughput","L2 Throughput (Reads)",370.193517GB/s,861.087017GB/s,615.429814GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)",12,"l2_read_throughput","L2 Throughput (Reads)",21.640691GB/s,530.586601GB/s,351.135586GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, int>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, int>(Eigen::internal::SumReducer<float>, float, long=1, float, Eigen::internal::SumReducer<float>::CoeffReturnType*)",10,"l2_read_throughput","L2 Throughput (Reads)",736.889603MB/s,774.567340MB/s,760.293125MB/s
"Tesla V100-SXM2-16GB (0)","void fft1d_c2r_32<float2, float, float, bool=0, bool=1, bool=0, bool=0>(float*, float2 const *, int, int3, int3, int2, int, float, float, float*, float*)",136,"l2_read_throughput","L2 Throughput (Reads)",139.756441GB/s,543.007359GB/s,332.388740GB/s
"Tesla V100-SXM2-16GB (0)","void cgemm_largek<bool=1, bool=0, bool=0, bool=0, int=4, int=4, int=4, int=3, int=3, int=18>(float2*, float2 const *, float2 const *, int, int, int, int, int, int, float2 const *, float2 const *, float2, float2, int, int, int*, int*)",1152,"l2_read_throughput","L2 Throughput (Reads)",146.741202GB/s,342.793810GB/s,268.398979GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_nn",12,"l2_read_throughput","L2 Throughput (Reads)",200.733606GB/s,522.623068GB/s,421.971924GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<__int64, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<__int64, __int64, Eigen::internal::scalar_max_op<__int64, __int64>>, Eigen::TensorMap<Eigen::Tensor<__int64 const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(__int64, int=1)",1,"l2_read_throughput","L2 Throughput (Reads)",449.700084MB/s,449.700084MB/s,449.699841MB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=0, int=1, int=128, int=8, int=8, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",24,"l2_read_throughput","L2 Throughput (Reads)",366.839888GB/s,380.196886GB/s,377.928533GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_nt",18,"l2_read_throughput","L2 Throughput (Reads)",247.291626GB/s,477.915180GB/s,359.700889GB/s
"Tesla V100-SXM2-16GB (0)","void cub::DeviceReduceSingleTileKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float*, float*, int, cub::Sum, float>(int, cub::Sum, cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float*, float*)",90,"l2_read_throughput","L2 Throughput (Reads)",234.860092MB/s,1.459770GB/s,533.047761MB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_splitK_xregs_large_nn_v1",4,"l2_read_throughput","L2 Throughput (Reads)",136.423591GB/s,136.613948GB/s,136.554226GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)",24,"l2_read_throughput","L2 Throughput (Reads)",6.837003GB/s,133.550834GB/s,89.434342GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",8,"l2_read_throughput","L2 Throughput (Reads)",119.525543GB/s,386.479312GB/s,361.963642GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",1880,"l2_read_throughput","L2 Throughput (Reads)",101.051582MB/s,909.927788MB/s,154.949083MB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=2, int=2, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",12,"l2_read_throughput","L2 Throughput (Reads)",416.876726GB/s,430.243410GB/s,422.724829GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_16x16<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",66,"l2_read_throughput","L2 Throughput (Reads)",210.437842GB/s,711.774484GB/s,649.492938GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_splitK_interior_nn_v1",88,"l2_read_throughput","L2 Throughput (Reads)",66.874762GB/s,782.643151GB/s,319.443440GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",110,"l2_read_throughput","L2 Throughput (Reads)",223.200372MB/s,809.368334MB/s,295.684543MB/s
"Tesla V100-SXM2-16GB (0)","void transpose_readWrite_alignment_kernel<float2, float2, int=1, bool=0, int=6, int=4, int=4>(cublasTransposeParams<float2>, float2 const *, float2*, float2 const *)",36,"l2_read_throughput","L2 Throughput (Reads)",325.641755GB/s,382.580650GB/s,372.776889GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, int>(Eigen::internal::SumReducer<float>, float, long=1, float, Eigen::internal::SumReducer<float>::CoeffReturnType*)",10,"l2_read_throughput","L2 Throughput (Reads)",2.263342GB/s,2.285322GB/s,2.275474GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_32x32<float, bool=0, unsigned int=1, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*)",82,"l2_read_throughput","L2 Throughput (Reads)",288.158823GB/s,704.363073GB/s,582.283700GB/s
"Tesla V100-SXM2-16GB (0)","void scal_kernel<float2, float2, int=1, bool=1, int=6, int=4, int=4, int=4>(cublasTransposeParams<float2>, float2 const *, float2*, float2 const *)",1152,"l2_read_throughput","L2 Throughput (Reads)",352.125901MB/s,2.838316GB/s,652.523450MB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const , float const , Eigen::internal::ComparisonName>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",940,"l2_read_throughput","L2 Throughput (Reads)",188.157695GB/s,518.980068GB/s,435.594686GB/s
