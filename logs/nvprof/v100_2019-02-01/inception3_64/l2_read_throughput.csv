==21628== NVPROF is profiling process 21628, command: python tf_cnn_benchmarks.py --num_gpus=1 --batch_size=64 --num_batches=10 --num_warmup_batches=0 --model=inception3 --data_dir=/home/keshavsanthanam/data/imagenet --allow_growth
2019-02-01 13:42:04.722582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-02-01 13:42:04.723184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:04.0
totalMemory: 15.75GiB freeMemory: 15.33GiB
2019-02-01 13:42:04.723214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-02-01 13:42:05.635478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-02-01 13:42:05.635521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-02-01 13:42:05.635529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-02-01 13:42:05.635895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14837 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
W0201 13:42:10.376702 139863567933824 tf_logging.py:125] From /home/keshavsanthanam/gpusched/workloads/tensorflow/image_classification/benchmark_cnn.py:2250: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2019-02-01 13:42:11.248797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-02-01 13:42:11.248910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-02-01 13:42:11.248936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-02-01 13:42:11.248948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-02-01 13:42:11.249714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14837 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
I0201 13:42:14.025825 139863567933824 tf_logging.py:115] Running local_init_op.
I0201 13:42:46.389242 139863567933824 tf_logging.py:115] Done running local_init_op.
TensorFlow:  1.12
Model:       inception3
Dataset:     imagenet
Mode:        training
SingleSess:  False
Batch size:  64 global
             64 per device
Num batches: 10
Num epochs:  0.00
Devices:     ['/gpu:0']
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
==========
start:2019-02-01 13:42:05.638487
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 0.9 +/- 0.0 (jitter = 0.0)	7.334
10	images/sec: 2.6 +/- 0.2 (jitter = 0.1)	7.432
----------------------------------------------------------------
total images/sec: 2.56
----------------------------------------------------------------
end:2019-02-01 13:46:56.839958
==21628== Profiling application: python tf_cnn_benchmarks.py --num_gpus=1 --batch_size=64 --num_batches=10 --num_warmup_batches=0 --model=inception3 --data_dir=/home/keshavsanthanam/data/imagenet --allow_growth
==21628== Profiling result:
==21628== Metric result:
"Device","Kernel","Invocations","Metric Name","Metric Description","Min","Max","Avg"
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",2955,"l2_read_throughput","L2 Throughput (Reads)",52.170367MB/s,511.844192GB/s,79.838979GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const , float const >, Eigen::TensorBroadcastingOp<Eigen::array<long, unsigned long=1> const , Eigen::TensorReshapingOp<Eigen::Sizes<> const , Eigen::TensorMap<Eigen::TensorFixedSize<float const , Eigen::Sizes<>, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1900,"l2_read_throughput","L2 Throughput (Reads)",130.371207MB/s,455.864627GB/s,152.286810GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",90,"l2_read_throughput","L2 Throughput (Reads)",591.379198GB/s,620.025773GB/s,614.042609GB/s
"Tesla V100-SXM2-16GB (0)","void flip_filter<float, float>(float*, float const *, int, int, int, int)",136,"l2_read_throughput","L2 Throughput (Reads)",12.297208GB/s,166.123322GB/s,42.477610GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::MaxReducer<float>, int>(Eigen::internal::MaxReducer<float>, float, long=1, float, Eigen::internal::MaxReducer<float>::CoeffReturnType*)",10,"l2_read_throughput","L2 Throughput (Reads)",4.460311GB/s,4.639394GB/s,4.538384GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=4, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, int=4> const , Eigen::DSizes<int, int=4> const , Eigen::TensorMap<Eigen::Tensor<float const , int=4, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=4)",460,"l2_read_throughput","L2 Throughput (Reads)",214.723290GB/s,339.927468GB/s,310.777842GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)",12,"l2_read_throughput","L2 Throughput (Reads)",186.219360GB/s,316.043938GB/s,284.647711GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1880,"l2_read_throughput","L2 Throughput (Reads)",66.924513MB/s,1.401338GB/s,516.390432MB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",12,"l2_read_throughput","L2 Throughput (Reads)",182.585712GB/s,466.481356GB/s,445.060073GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",14,"l2_read_throughput","L2 Throughput (Reads)",159.202247GB/s,710.753219GB/s,484.360486GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",20,"l2_read_throughput","L2 Throughput (Reads)",582.535228GB/s,591.609325GB/s,588.153123GB/s
"Tesla V100-SXM2-16GB (0)","void fft1d_c2r_32<float2, float, float, bool=0, bool=1, bool=0, bool=1>(float*, float2 const *, int, int3, int3, int2, int, float, float, float*, float*)",24,"l2_read_throughput","L2 Throughput (Reads)",342.957662GB/s,506.378317GB/s,391.766291GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeBOffsetsKernel(cudnn::gemm::ComputeBOffsetsParams)",76,"l2_read_throughput","L2 Throughput (Reads)",141.285084MB/s,530.884750MB/s,352.792071MB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_splitK_small_nn_v1",12,"l2_read_throughput","L2 Throughput (Reads)",243.688099GB/s,335.965666GB/s,279.699128GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",212,"l2_read_throughput","L2 Throughput (Reads)",416.565374GB/s,755.412923GB/s,595.299584GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=1, int=2, int=128, int=8, int=8, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",12,"l2_read_throughput","L2 Throughput (Reads)",382.545543GB/s,386.400717GB/s,385.164861GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeWgradBOffsetsKernel(cudnn::gemm::ComputeBOffsetsParams)",172,"l2_read_throughput","L2 Throughput (Reads)",139.988890MB/s,0.985201GB/s,292.163880MB/s
"Tesla V100-SXM2-16GB (0)","void scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)",1104,"l2_read_throughput","L2 Throughput (Reads)",5.148664MB/s,2.416405GB/s,64.129230MB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x128_nn",6,"l2_read_throughput","L2 Throughput (Reads)",154.942520GB/s,270.706571GB/s,198.117336GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_splitK_interior_nn_v1",20,"l2_read_throughput","L2 Throughput (Reads)",174.852013GB/s,341.793097GB/s,268.974052GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x128_nt",12,"l2_read_throughput","L2 Throughput (Reads)",43.707019GB/s,276.736069GB/s,101.148183GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=6, int=5, int=4, int=4, bool=1, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=6, int=5, int=4, int=4, bool=1, bool=1>*, kernel_grad_params, int, int, float, int, int)",24,"l2_read_throughput","L2 Throughput (Reads)",383.441479GB/s,613.507966GB/s,583.102734GB/s
"Tesla V100-SXM2-16GB (0)","void pointwise_mult_and_sum_complex<float2, int=8, int=4>(float2*, float2*, float2*, int, int, int, int, int, float2)",8,"l2_read_throughput","L2 Throughput (Reads)",878.780015GB/s,1022.076110GB/s,955.168159GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",90,"l2_read_throughput","L2 Throughput (Reads)",110.543638GB/s,509.360248GB/s,172.287116GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_relu_interior_nn_v1",12,"l2_read_throughput","L2 Throughput (Reads)",185.655784GB/s,332.308628GB/s,241.703589GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_small_nn_v1",12,"l2_read_throughput","L2 Throughput (Reads)",150.304725GB/s,194.976154GB/s,158.795133GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasNHWCKernel<float>(int, float const *, float const , tensorflow::BiasNHWCKernel<float>*, int)",10,"l2_read_throughput","L2 Throughput (Reads)",89.699039GB/s,96.555016GB/s,94.449455GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(cudnnTensorStruct, float const *, cudnn::detail::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::detail::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",940,"l2_read_throughput","L2 Throughput (Reads)",164.871842GB/s,259.882812GB/s,224.493939GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1000,"l2_read_throughput","L2 Throughput (Reads)",1.800557GB/s,505.977470GB/s,265.525685GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_sum_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",491.738319MB/s,511.727681MB/s,505.562073MB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, int=1024, int=1024, int=2, bool=0>(unsigned int const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, int=1024, int=1024, int=2, bool=0>*)",10,"l2_read_throughput","L2 Throughput (Reads)",491.656126GB/s,500.129591GB/s,497.209591GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)",2,"l2_read_throughput","L2 Throughput (Reads)",236.543825GB/s,253.412153GB/s,244.680725GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",472,"l2_read_throughput","L2 Throughput (Reads)",483.327563GB/s,859.388159GB/s,566.936909GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)",2,"l2_read_throughput","L2 Throughput (Reads)",177.798928GB/s,184.782349GB/s,181.202438GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1>*, kernel_grad_params, int, int, float, int, int, int)",474,"l2_read_throughput","L2 Throughput (Reads)",706.624676GB/s,898.248787GB/s,749.607907GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",940,"l2_read_throughput","L2 Throughput (Reads)",204.003202GB/s,490.064927GB/s,355.111578GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",270,"l2_read_throughput","L2 Throughput (Reads)",238.308144GB/s,463.599960GB/s,351.700080GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1880,"l2_read_throughput","L2 Throughput (Reads)",84.070462MB/s,1.199670GB/s,510.117848MB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_splitK_medium_nn_v1",12,"l2_read_throughput","L2 Throughput (Reads)",356.418681GB/s,399.285567GB/s,377.332370GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_32x32<float, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*)",284,"l2_read_throughput","L2 Throughput (Reads)",104.530923GB/s,437.240252GB/s,149.974304GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",2,"l2_read_throughput","L2 Throughput (Reads)",380.312495GB/s,440.873855GB/s,408.354842GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_small_nn_v1",26,"l2_read_throughput","L2 Throughput (Reads)",177.488448GB/s,274.698608GB/s,235.663320GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_relu_small_nn_v1",26,"l2_read_throughput","L2 Throughput (Reads)",179.988556GB/s,280.936283GB/s,232.723939GB/s
"Tesla V100-SXM2-16GB (0)","volta_cgemm_32x32_tn",1638,"l2_read_throughput","L2 Throughput (Reads)",187.637106GB/s,702.562285GB/s,530.570476GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_clip<int=1, int=2, int=256, int=16, int=16, int=1, float, float, float2>(float*, float2*, int, int3, float2*, int, float2*, float2*, int, int, int, int, int, float, float, bool, int, float, float)",12,"l2_read_throughput","L2 Throughput (Reads)",302.984418GB/s,327.398242GB/s,308.795019GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorBroadcastingOp<Eigen::array<int, unsigned long=1> const , Eigen::TensorReshapingOp<Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorMap<Eigen::TensorFixedSize<bool const , Eigen::Sizes<>, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",408.717564MB/s,452.823775MB/s,440.773635MB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",402,"l2_read_throughput","L2 Throughput (Reads)",147.404176GB/s,958.149960GB/s,523.256068GB/s
"Tesla V100-SXM2-16GB (0)","void fft1d_r2c_32<float, float, float2, bool=0, bool=0>(float2*, float const *, int, int3, int3, int2, int2)",198,"l2_read_throughput","L2 Throughput (Reads)",2.391584GB/s,263.680877GB/s,118.038110GB/s
"Tesla V100-SXM2-16GB (0)","void fft1d_r2c_32<float, float, float2, bool=1, bool=0>(float2*, float const *, int, int3, int3, int2, int2)",62,"l2_read_throughput","L2 Throughput (Reads)",10.722238GB/s,87.847697GB/s,72.084948GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::BlockReduceKernel<cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int=256, cub::Sum>(float, float, int, float*, std::iterator_traits<tensorflow::functor::BlockReduceKernel<cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int=256, cub::Sum>>::value_type)",870,"l2_read_throughput","L2 Throughput (Reads)",753.220479MB/s,68.147715GB/s,50.101854GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",24,"l2_read_throughput","L2 Throughput (Reads)",171.092220GB/s,392.775461GB/s,368.744276GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, unsigned long=2> const , Eigen::array<int, unsigned long=2> const , Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>>, Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::GpuDevice>, int>(int, unsigned long=2)",460,"l2_read_throughput","L2 Throughput (Reads)",187.024778GB/s,349.253761GB/s,321.793748GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",6,"l2_read_throughput","L2 Throughput (Reads)",126.166548GB/s,137.471559GB/s,132.940262GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=1, int=4, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",16,"l2_read_throughput","L2 Throughput (Reads)",990.979981GB/s,1133.432269GB/s,1122.171621GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_bw_kernel_avg<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>(cudnnTensorStruct, float const *, float const , cudnn::detail::pooling_bw_kernel_avg<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>, float const , cudnn::detail::pooling_bw_kernel_avg<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",90,"l2_read_throughput","L2 Throughput (Reads)",2.487816GB/s,99.641189GB/s,77.143205GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_64x64<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",60,"l2_read_throughput","L2 Throughput (Reads)",324.085965GB/s,641.918580GB/s,509.905417GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::ShuffleInTensor3Simple<float, int=2, int=1, int=0, bool=0>(int, float const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::ShuffleInTensor3Simple<float, int=2, int=1, int=0, bool=0>*)",2810,"l2_read_throughput","L2 Throughput (Reads)",783.149769MB/s,1183.944970GB/s,623.988026GB/s
"Tesla V100-SXM2-16GB (0)","volta_gcgemm_32x32_nt",276,"l2_read_throughput","L2 Throughput (Reads)",417.294228GB/s,908.877992GB/s,805.408699GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_16x16<float>(float2*, float const *, int, int, int, int, int, int, int, int)",132,"l2_read_throughput","L2 Throughput (Reads)",2.585878GB/s,126.241978GB/s,38.740748GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::TruncatedNormalDistribution<tensorflow::random::SingleSampleAdapter<tensorflow::random::PhiloxRandom>, float>>(tensorflow::random::PhiloxRandom, tensorflow::random::PhiloxRandomResultElementType*, __int64, tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::TruncatedNormalDistribution<tensorflow::random::SingleSampleAdapter<tensorflow::random::PhiloxRandom>, float>>)",95,"l2_read_throughput","L2 Throughput (Reads)",334.921337MB/s,38.566485GB/s,16.751416GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_clip<int=1, int=2, int=128, int=16, int=32, int=1, float, float, float2>(float*, float2*, int, int3, float2*, int, float2*, float2*, int, int, int, int, int, float, float, bool, int, float, float)",12,"l2_read_throughput","L2 Throughput (Reads)",302.585708GB/s,340.935527GB/s,319.950429GB/s
"Tesla V100-SXM2-16GB (0)","volta_cgemm_64x32_tn",12,"l2_read_throughput","L2 Throughput (Reads)",361.538583GB/s,541.702676GB/s,478.895296GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeWgradSplitKOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",172,"l2_read_throughput","L2 Throughput (Reads)",383.065834MB/s,3.547896GB/s,1.602879GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_splitK_small_nn_v1",40,"l2_read_throughput","L2 Throughput (Reads)",366.575466GB/s,927.873719GB/s,639.702111GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",4,"l2_read_throughput","L2 Throughput (Reads)",559.779301GB/s,562.336663GB/s,560.726202GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, int=0, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, int=0, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",50,"l2_read_throughput","L2 Throughput (Reads)",145.409625GB/s,713.994618GB/s,524.956709GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, unsigned long=2> const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",45.503918GB/s,47.839317GB/s,47.241975GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",388,"l2_read_throughput","L2 Throughput (Reads)",29.803067GB/s,304.280116GB/s,177.899483GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=1, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",12,"l2_read_throughput","L2 Throughput (Reads)",4.555548GB/s,9.597898GB/s,9.272842GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",124,"l2_read_throughput","L2 Throughput (Reads)",8.015797GB/s,270.695559GB/s,72.017181GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=4, int=6, int=3, int=2, int=4, bool=1, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=4, int=6, int=3, int=2, int=4, bool=1, bool=1>*, kernel_grad_params, int, int, float, int, int)",4,"l2_read_throughput","L2 Throughput (Reads)",1202.214003GB/s,1275.453243GB/s,1247.625068GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=5, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",2,"l2_read_throughput","L2 Throughput (Reads)",12.843359GB/s,13.061720GB/s,12.941285GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, int>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",49.449017GB/s,51.520180GB/s,51.039182GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_relu_interior_nn_v1",34,"l2_read_throughput","L2 Throughput (Reads)",268.136788GB/s,562.727145GB/s,369.136111GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1>*, kernel_grad_params, int, int, float, int, int, int)",194,"l2_read_throughput","L2 Throughput (Reads)",720.965419GB/s,800.448750GB/s,770.602862GB/s
"Tesla V100-SXM2-16GB (0)","volta_gcgemm_64x32_nt",172,"l2_read_throughput","L2 Throughput (Reads)",288.116179GB/s,737.065221GB/s,663.871511GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_32x128_nn",10,"l2_read_throughput","L2 Throughput (Reads)",312.813823GB/s,370.140618GB/s,336.853924GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",52.351431GB/s,53.775959GB/s,53.089765GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::BlockReduceKernel<float*, float*, int=256, tensorflow::functor::Sum<float>>(float*, float*, int, float, std::iterator_traits<tensorflow::functor::BlockReduceKernel<float*, float*, int=256, tensorflow::functor::Sum<float>>>::value_type)",10,"l2_read_throughput","L2 Throughput (Reads)",873.594793MB/s,880.314754MB/s,875.599756MB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>>::value_type)",850,"l2_read_throughput","L2 Throughput (Reads)",40.932973MB/s,680.139822MB/s,180.292961MB/s
"Tesla V100-SXM2-16GB (0)","void pooling_bw_kernel_max_nchw_fully_packed_large<float, float, int=3, cudnnNanPropagation_t=0>(cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, int)",10,"l2_read_throughput","L2 Throughput (Reads)",187.555733GB/s,188.560829GB/s,188.048464GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_32x128_nt",10,"l2_read_throughput","L2 Throughput (Reads)",560.448022GB/s,582.533663GB/s,572.507591GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)",24,"l2_read_throughput","L2 Throughput (Reads)",336.005485GB/s,450.849794GB/s,355.368688GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",278.445055MB/s,800.286139MB/s,660.756097MB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=1, int=2, int=256, int=16, int=16, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",12,"l2_read_throughput","L2 Throughput (Reads)",375.906506GB/s,377.801731GB/s,376.895445GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_tn",10,"l2_read_throughput","L2 Throughput (Reads)",213.144760GB/s,239.407868GB/s,232.385315GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x32_relu_interior_nn_v1",6,"l2_read_throughput","L2 Throughput (Reads)",212.336016GB/s,576.245400GB/s,309.108089GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorReshapingOp<Eigen::IndexList<int> const , Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>> const > const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",49.256007GB/s,51.688403GB/s,50.748614GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_interior_nn_v1",14,"l2_read_throughput","L2 Throughput (Reads)",306.226871GB/s,535.849483GB/s,460.385444GB/s
"Tesla V100-SXM2-16GB (0)","void cub::DeviceReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int, cub::Sum>(int, cub::Sum, cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, cub::GridEvenShare<cub::Sum>, float)",90,"l2_read_throughput","L2 Throughput (Reads)",247.932397GB/s,423.643172GB/s,348.824570GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=512, int=6, int=8, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=512, int=6, int=8, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",146,"l2_read_throughput","L2 Throughput (Reads)",274.147258GB/s,304.442536GB/s,282.325727GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",10,"l2_read_throughput","L2 Throughput (Reads)",410.749267GB/s,433.049063GB/s,423.058520GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_pad<int=0, int=1, int=256, int=16, int=16, int=1, float, float, float2>(float2*, float*, int, int3, float*, int, float*, float*, int, int, int, int, int, bool)",24,"l2_read_throughput","L2 Throughput (Reads)",261.437960MB/s,204.449511GB/s,156.306314GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::ColumnReduceKernel<float const *, float*, cub::Sum>(float const *, float*, int, int, cub::Sum, std::iterator_traits<tensorflow::functor::ColumnReduceKernel<float const *, float*, cub::Sum>>::value_type)",1,"l2_read_throughput","L2 Throughput (Reads)",62.804574GB/s,62.804574GB/s,62.804573GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)",4,"l2_read_throughput","L2 Throughput (Reads)",33.458626GB/s,36.657697GB/s,34.947101GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=1, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",68,"l2_read_throughput","L2 Throughput (Reads)",643.871646MB/s,30.982080GB/s,5.712458GB/s
"Tesla V100-SXM2-16GB (0)","void pooling_bw_kernel_max_nchw_fully_packed_small<float, float, int=3, cudnnNanPropagation_t=0>(cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor)",30,"l2_read_throughput","L2 Throughput (Reads)",125.781183GB/s,341.085689GB/s,220.286153GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",162,"l2_read_throughput","L2 Throughput (Reads)",132.685122MB/s,3.753300GB/s,1.359608GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=5, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",2,"l2_read_throughput","L2 Throughput (Reads)",10.475758GB/s,10.530160GB/s,10.506099GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_relu_small_nn_v1",4,"l2_read_throughput","L2 Throughput (Reads)",173.368573GB/s,198.849473GB/s,185.625327GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>(float, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnnTensorStruct, float const *, float, float const , float, cudnnTensorStruct*, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const *, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>*, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const *, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const , cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const , cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>)",30,"l2_read_throughput","L2 Throughput (Reads)",303.453625GB/s,458.723314GB/s,365.418404GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(float, float, float, float, cudnnTensorStruct, float const *, cudnn::detail::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, float const , cudnn::detail::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::detail::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",910,"l2_read_throughput","L2 Throughput (Reads)",262.929143GB/s,402.293115GB/s,350.046801GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::ReductionInitKernel<float, int>(float, int, Eigen::internal::ReductionInitKernel<float, int>*)",30,"l2_read_throughput","L2 Throughput (Reads)",30.763687MB/s,436.095192MB/s,225.458820MB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_64x64<float>(float2*, float const *, int, int, int, int, int, int, int, int)",120,"l2_read_throughput","L2 Throughput (Reads)",1.055303GB/s,158.737211GB/s,94.314137GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const *, tensorflow::BiasGradNHWC_SharedAtomics<float>*, int)",10,"l2_read_throughput","L2 Throughput (Reads)",87.918992GB/s,91.058956GB/s,90.199909GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",196,"l2_read_throughput","L2 Throughput (Reads)",203.366358GB/s,383.393067GB/s,291.903527GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>, float const , cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>, float const , cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",10,"l2_read_throughput","L2 Throughput (Reads)",620.733718GB/s,635.541704GB/s,627.326968GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_pad<int=0, int=1, int=128, int=16, int=32, int=1, float, float, float2>(float2*, float*, int, int3, float*, int, float*, float*, int, int, int, int, int, bool)",24,"l2_read_throughput","L2 Throughput (Reads)",400.444982MB/s,189.384848GB/s,110.455056GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x32_relu_small_nn_v1",4,"l2_read_throughput","L2 Throughput (Reads)",173.607945GB/s,191.156692GB/s,184.659353GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",18,"l2_read_throughput","L2 Throughput (Reads)",430.176725GB/s,933.711200GB/s,772.340068GB/s
"Tesla V100-SXM2-16GB (0)","void fft1d_r2c_32<float, float, float2, bool=0, bool=1>(float2*, float const *, int, int3, int3, int2, int2)",24,"l2_read_throughput","L2 Throughput (Reads)",96.086223GB/s,204.783632GB/s,181.306438GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)",4,"l2_read_throughput","L2 Throughput (Reads)",801.402289GB/s,836.391081GB/s,825.318274GB/s
"Tesla V100-SXM2-16GB (0)","void im2col4d_kernel<float, int>(im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const *, float*, int)",86,"l2_read_throughput","L2 Throughput (Reads)",26.052701GB/s,310.984711GB/s,123.679351GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=0, int=1, int=256, int=16, int=16, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",24,"l2_read_throughput","L2 Throughput (Reads)",369.506719GB/s,374.827584GB/s,373.609434GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",12,"l2_read_throughput","L2 Throughput (Reads)",320.485370GB/s,359.231093GB/s,331.131147GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=4, int=1, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",96,"l2_read_throughput","L2 Throughput (Reads)",425.471998GB/s,930.627470GB/s,759.429468GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_interior_nn_v1",24,"l2_read_throughput","L2 Throughput (Reads)",155.810165GB/s,368.603539GB/s,310.454665GB/s
"Tesla V100-SXM2-16GB (0)","compute_gemm_pointers(float2**, float2 const *, int, float2 const *, int, float2 const *, int, int)",210,"l2_read_throughput","L2 Throughput (Reads)",50.947542MB/s,2.235756GB/s,831.032743MB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1>*, kernel_grad_params, int, int, float, int, int, int)",226,"l2_read_throughput","L2 Throughput (Reads)",905.663273GB/s,1070.450875GB/s,1003.541881GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",342,"l2_read_throughput","L2 Throughput (Reads)",468.009235GB/s,911.947565GB/s,693.169021GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)",12,"l2_read_throughput","L2 Throughput (Reads)",22.160701GB/s,520.626130GB/s,355.312050GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, int>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, int>(Eigen::internal::SumReducer<float>, float, long=1, float, Eigen::internal::SumReducer<float>::CoeffReturnType*)",10,"l2_read_throughput","L2 Throughput (Reads)",1.409797GB/s,1.506313GB/s,1.444331GB/s
"Tesla V100-SXM2-16GB (0)","void fft1d_c2r_32<float2, float, float, bool=0, bool=1, bool=0, bool=0>(float*, float2 const *, int, int3, int3, int2, int, float, float, float*, float*)",136,"l2_read_throughput","L2 Throughput (Reads)",129.688714GB/s,599.699106GB/s,353.898667GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_nn",10,"l2_read_throughput","L2 Throughput (Reads)",228.304992GB/s,492.295930GB/s,411.081050GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<__int64, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<__int64, __int64, Eigen::internal::scalar_max_op<__int64, __int64>>, Eigen::TensorMap<Eigen::Tensor<__int64 const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(__int64, int=1)",1,"l2_read_throughput","L2 Throughput (Reads)",425.485464MB/s,425.485464MB/s,425.485234MB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=0, int=1, int=128, int=8, int=8, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",24,"l2_read_throughput","L2 Throughput (Reads)",376.934004GB/s,380.142631GB/s,379.120104GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_nt",14,"l2_read_throughput","L2 Throughput (Reads)",276.303760GB/s,499.596136GB/s,399.933217GB/s
"Tesla V100-SXM2-16GB (0)","void cub::DeviceReduceSingleTileKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float*, float*, int, cub::Sum, float>(int, cub::Sum, cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float*, float*)",90,"l2_read_throughput","L2 Throughput (Reads)",138.341644MB/s,1.422079GB/s,518.671627MB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_splitK_xregs_large_nn_v1",4,"l2_read_throughput","L2 Throughput (Reads)",137.730919GB/s,137.803331GB/s,137.781179GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)",24,"l2_read_throughput","L2 Throughput (Reads)",7.034089GB/s,137.291471GB/s,90.674722GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",38,"l2_read_throughput","L2 Throughput (Reads)",127.936585GB/s,455.036113GB/s,362.141590GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",1880,"l2_read_throughput","L2 Throughput (Reads)",29.121563MB/s,803.094161MB/s,162.561005MB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=2, int=2, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",12,"l2_read_throughput","L2 Throughput (Reads)",413.024229GB/s,419.518227GB/s,416.805084GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_16x16<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",66,"l2_read_throughput","L2 Throughput (Reads)",339.593823GB/s,709.514198GB/s,638.346448GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_splitK_interior_nn_v1",84,"l2_read_throughput","L2 Throughput (Reads)",111.417221GB/s,993.569293GB/s,446.798504GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",110,"l2_read_throughput","L2 Throughput (Reads)",233.120388MB/s,860.307600MB/s,315.652237MB/s
"Tesla V100-SXM2-16GB (0)","void transpose_readWrite_alignment_kernel<float2, float2, int=1, bool=0, int=6, int=4, int=4>(cublasTransposeParams<float2>, float2 const *, float2*, float2 const *)",228,"l2_read_throughput","L2 Throughput (Reads)",355.266521GB/s,382.582920GB/s,374.705181GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, int>(Eigen::internal::SumReducer<float>, float, long=1, float, Eigen::internal::SumReducer<float>::CoeffReturnType*)",10,"l2_read_throughput","L2 Throughput (Reads)",4.628030GB/s,4.873481GB/s,4.826789GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_32x32<float, bool=0, unsigned int=1, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*)",82,"l2_read_throughput","L2 Throughput (Reads)",380.105008GB/s,708.697898GB/s,553.478113GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const , float const , Eigen::internal::ComparisonName>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",940,"l2_read_throughput","L2 Throughput (Reads)",341.421294GB/s,516.748532GB/s,490.341874GB/s
