==14978== NVPROF is profiling process 14978, command: python tf_cnn_benchmarks.py --num_gpus=1 --batch_size=16 --num_batches=10 --num_warmup_batches=0 --model=vgg16 --data_dir=/home/keshavsanthanam/data/imagenet --allow_growth
2018-12-26 05:09:50.465983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-26 05:09:50.466570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:04.0
totalMemory: 15.75GiB freeMemory: 15.33GiB
2018-12-26 05:09:50.466598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-26 05:09:51.367874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-26 05:09:51.367920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-26 05:09:51.367927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-26 05:09:51.368299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14837 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
W1226 05:09:52.191355 139840979018112 tf_logging.py:125] From /home/keshavsanthanam/dl_scheduling/workloads/tensorflow/image_classification/benchmark_cnn.py:2250: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2018-12-26 05:09:52.293585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-26 05:09:52.293657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-26 05:09:52.293663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-26 05:09:52.293669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-26 05:09:52.294031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14837 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
I1226 05:09:52.753508 139840979018112 tf_logging.py:115] Running local_init_op.
I1226 05:10:24.473073 139840979018112 tf_logging.py:115] Done running local_init_op.
TensorFlow:  1.12
Model:       vgg16
Dataset:     imagenet
Mode:        training
SingleSess:  False
Batch size:  16 global
             16 per device
Num batches: 10
Num epochs:  0.00
Devices:     ['/gpu:0']
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
==========
start:2018-12-26 05:09:51.371566
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 0.6 +/- 0.0 (jitter = 0.0)	7.255
10	images/sec: 3.1 +/- 0.5 (jitter = 0.1)	7.264
----------------------------------------------------------------
total images/sec: 3.05
----------------------------------------------------------------
end:2018-12-26 05:11:17.097224
==14978== Profiling application: python tf_cnn_benchmarks.py --num_gpus=1 --batch_size=16 --num_batches=10 --num_warmup_batches=0 --model=vgg16 --data_dir=/home/keshavsanthanam/data/imagenet --allow_growth
==14978== Profiling result:
==14978== Metric result:
"Device","Kernel","Invocations","Metric Name","Metric Description","Min","Max","Avg"
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",356,"l2_read_throughput","L2 Throughput (Reads)",77.330882MB/s,420.467934GB/s,350.158773GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const , float const >, Eigen::TensorBroadcastingOp<Eigen::array<long, unsigned long=1> const , Eigen::TensorReshapingOp<Eigen::Sizes<> const , Eigen::TensorMap<Eigen::TensorFixedSize<float const , Eigen::Sizes<>, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",320,"l2_read_throughput","L2 Throughput (Reads)",192.029444MB/s,513.864696GB/s,483.505211GB/s
"Tesla V100-SXM2-16GB (0)","void flip_filter<float, float>(float*, float const *, int, int, int, int)",20,"l2_read_throughput","L2 Throughput (Reads)",34.348386GB/s,178.034505GB/s,65.244610GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::MaxReducer<float>, int>(Eigen::internal::MaxReducer<float>, float, long=1, float, Eigen::internal::MaxReducer<float>::CoeffReturnType*)",10,"l2_read_throughput","L2 Throughput (Reads)",2.159102GB/s,2.240391GB/s,2.195456GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)",18,"l2_read_throughput","L2 Throughput (Reads)",165.689889GB/s,244.965159GB/s,196.852461GB/s
"Tesla V100-SXM2-16GB (0)","void pooling_bw_kernel_max_nchw_fully_packed_small<float, float, int=2, cudnnNanPropagation_t=0>(cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor)",20,"l2_read_throughput","L2 Throughput (Reads)",224.410327GB/s,340.573253GB/s,303.599061GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",18,"l2_read_throughput","L2 Throughput (Reads)",165.017642GB/s,540.561638GB/s,479.012745GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",2,"l2_read_throughput","L2 Throughput (Reads)",189.528226GB/s,190.534377GB/s,190.029805GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeBOffsetsKernel(cudnn::gemm::ComputeBOffsetsParams)",16,"l2_read_throughput","L2 Throughput (Reads)",224.393956MB/s,565.140335MB/s,402.268604MB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_splitK_small_nn_v1",8,"l2_read_throughput","L2 Throughput (Reads)",357.305994GB/s,358.609475GB/s,357.985225GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",24,"l2_read_throughput","L2 Throughput (Reads)",381.498016GB/s,609.942137GB/s,587.387451GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=1, int=2, int=128, int=8, int=8, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",12,"l2_read_throughput","L2 Throughput (Reads)",371.097280GB/s,386.759564GB/s,384.455038GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeWgradBOffsetsKernel(cudnn::gemm::ComputeBOffsetsParams)",36,"l2_read_throughput","L2 Throughput (Reads)",141.285084MB/s,657.706425MB/s,295.771489MB/s
"Tesla V100-SXM2-16GB (0)","void scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)",72,"l2_read_throughput","L2 Throughput (Reads)",8.901605MB/s,2.721082GB/s,56.148774MB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x128_nn",18,"l2_read_throughput","L2 Throughput (Reads)",31.431656GB/s,332.247117GB/s,204.193503GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x128_nt",10,"l2_read_throughput","L2 Throughput (Reads)",45.848118GB/s,338.950059GB/s,102.756429GB/s
"Tesla V100-SXM2-16GB (0)","void pointwise_mult_and_sum_complex<float2, int=8, int=4>(float2*, float2*, float2*, int, int, int, int, int, float2)",26,"l2_read_throughput","L2 Throughput (Reads)",367.488707GB/s,1463.796606GB/s,1122.633947GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_splitK_medium_nn_v1",8,"l2_read_throughput","L2 Throughput (Reads)",286.568307GB/s,288.105824GB/s,287.514036GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1",2,"l2_read_throughput","L2 Throughput (Reads)",302.148994GB/s,306.768975GB/s,304.440225GB/s
"Tesla V100-SXM2-16GB (0)","void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float const *, float*, cub::TransformInputIterator<int, tensorflow::functor::RowOffset, cub::CountingInputIterator<int, long>, long>, int, cub::Sum, float>(int, cub::Sum, cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, cub::Sum, int, float*, int)",3,"l2_read_throughput","L2 Throughput (Reads)",752.066847GB/s,792.095460GB/s,783.422076GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasGradNCHW_SharedAtomics<float>(float const *, tensorflow::BiasGradNCHW_SharedAtomics<float>*, int, int, int, int)",130,"l2_read_throughput","L2 Throughput (Reads)",256.755784GB/s,575.380332GB/s,529.273735GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_small_nn_v1",4,"l2_read_throughput","L2 Throughput (Reads)",215.655589GB/s,259.454850GB/s,237.677138GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasNHWCKernel<float>(int, float const *, float const , tensorflow::BiasNHWCKernel<float>*, int)",30,"l2_read_throughput","L2 Throughput (Reads)",29.164725GB/s,117.161802GB/s,86.072380GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",320,"l2_read_throughput","L2 Throughput (Reads)",260.834001MB/s,520.359585GB/s,486.384897GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_sum_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",528.928612MB/s,547.326129MB/s,540.742912MB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, int=1024, int=1024, int=2, bool=0>(unsigned int const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, int=1024, int=1024, int=2, bool=0>*)",10,"l2_read_throughput","L2 Throughput (Reads)",410.280746GB/s,447.854103GB/s,441.046365GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",100,"l2_read_throughput","L2 Throughput (Reads)",494.600781GB/s,619.413986GB/s,516.265068GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1>*, kernel_grad_params, int, int, float, int, int, int)",8,"l2_read_throughput","L2 Throughput (Reads)",619.145234GB/s,702.799576GB/s,661.540723GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x32_sliced1x4_tn",10,"l2_read_throughput","L2 Throughput (Reads)",535.202116GB/s,547.392009GB/s,542.238139GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",150,"l2_read_throughput","L2 Throughput (Reads)",58.475769GB/s,492.130455GB/s,370.184534GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_64x32_sliced1x4_nn",20,"l2_read_throughput","L2 Throughput (Reads)",630.245924GB/s,859.185836GB/s,828.048709GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_32x32<float, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*)",560,"l2_read_throughput","L2 Throughput (Reads)",82.668225GB/s,361.420608GB/s,144.665801GB/s
"Tesla V100-SXM2-16GB (0)","void pooling_bw_kernel_max_nchw_fully_packed_large<float, float, int=2, cudnnNanPropagation_t=0>(cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, int)",10,"l2_read_throughput","L2 Throughput (Reads)",254.726046GB/s,257.002114GB/s,255.929036GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",2,"l2_read_throughput","L2 Throughput (Reads)",458.740581GB/s,462.503990GB/s,460.620458GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_small_nn_v1",12,"l2_read_throughput","L2 Throughput (Reads)",228.976840GB/s,363.136086GB/s,294.737613GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_relu_small_nn_v1",10,"l2_read_throughput","L2 Throughput (Reads)",120.734039GB/s,299.561993GB/s,244.276813GB/s
"Tesla V100-SXM2-16GB (0)","volta_cgemm_32x32_tn",12,"l2_read_throughput","L2 Throughput (Reads)",439.640707GB/s,467.656656GB/s,458.846413GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_clip<int=1, int=2, int=256, int=16, int=16, int=1, float, float, float2>(float*, float2*, int, int3, float2*, int, float2*, float2*, int, int, int, int, int, float, float, bool, int, float, float)",10,"l2_read_throughput","L2 Throughput (Reads)",249.022020GB/s,329.301607GB/s,290.293827GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorBroadcastingOp<Eigen::array<int, unsigned long=1> const , Eigen::TensorReshapingOp<Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorMap<Eigen::TensorFixedSize<bool const , Eigen::Sizes<>, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",452.823775MB/s,469.720185MB/s,461.793653MB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_floor_op<float>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",20,"l2_read_throughput","L2 Throughput (Reads)",50.952358GB/s,71.470384GB/s,61.530405GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",24,"l2_read_throughput","L2 Throughput (Reads)",100.434437GB/s,623.593611GB/s,563.846337GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::BlockReduceKernel<cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int=256, cub::Sum>(float, float, int, float*, std::iterator_traits<tensorflow::functor::BlockReduceKernel<cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int=256, cub::Sum>>::value_type)",210,"l2_read_throughput","L2 Throughput (Reads)",180.221917MB/s,65.815836GB/s,17.118642GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",34,"l2_read_throughput","L2 Throughput (Reads)",158.603929GB/s,474.550705GB/s,435.009494GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=1, int=4, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",80,"l2_read_throughput","L2 Throughput (Reads)",1025.961291GB/s,1216.733741GB/s,1146.791319GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x32_tn",10,"l2_read_throughput","L2 Throughput (Reads)",390.150554GB/s,561.331643GB/s,467.460813GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_64x64<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",12,"l2_read_throughput","L2 Throughput (Reads)",267.524806GB/s,653.950401GB/s,567.291267GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::ShuffleInTensor3Simple<float, int=2, int=1, int=0, bool=0>(int, float const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::ShuffleInTensor3Simple<float, int=2, int=1, int=0, bool=0>*)",380,"l2_read_throughput","L2 Throughput (Reads)",1.652347GB/s,1237.946497GB/s,867.146039GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::RowReduceKernel<float const *, float*, cub::Sum>(float const *, float*, int, int, cub::Sum, std::iterator_traits<tensorflow::functor::RowReduceKernel<float const *, float*, cub::Sum>>::value_type)",2,"l2_read_throughput","L2 Throughput (Reads)",661.439066GB/s,702.719174GB/s,694.028624GB/s
"Tesla V100-SXM2-16GB (0)","volta_gcgemm_32x32_nt",556,"l2_read_throughput","L2 Throughput (Reads)",50.785393GB/s,676.266405GB/s,568.959963GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_16x16<float>(float2*, float const *, int, int, int, int, int, int, int, int)",12,"l2_read_throughput","L2 Throughput (Reads)",21.120381GB/s,262.507916GB/s,51.174101GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::TruncatedNormalDistribution<tensorflow::random::SingleSampleAdapter<tensorflow::random::PhiloxRandom>, float>>(tensorflow::random::PhiloxRandom, tensorflow::random::PhiloxRandomResultElementType*, __int64, tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::TruncatedNormalDistribution<tensorflow::random::SingleSampleAdapter<tensorflow::random::PhiloxRandom>, float>>)",16,"l2_read_throughput","L2 Throughput (Reads)",410.550378MB/s,36.103381GB/s,31.435336GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_clip<int=1, int=2, int=128, int=16, int=32, int=1, float, float, float2>(float*, float2*, int, int3, float2*, int, float2*, float2*, int, int, int, int, int, float, float, bool, int, float, float)",12,"l2_read_throughput","L2 Throughput (Reads)",236.335735GB/s,341.266674GB/s,317.947430GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeWgradSplitKOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",36,"l2_read_throughput","L2 Throughput (Reads)",738.328503MB/s,3.492460GB/s,1.602054GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_splitK_small_nn_v1",4,"l2_read_throughput","L2 Throughput (Reads)",627.822002GB/s,635.135263GB/s,630.757636GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",2,"l2_read_throughput","L2 Throughput (Reads)",736.811971GB/s,741.675584GB/s,739.243081GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, int=0, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, int=0, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",50,"l2_read_throughput","L2 Throughput (Reads)",383.276077GB/s,593.201316GB/s,563.920353GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, unsigned long=2> const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",14.268071GB/s,14.939510GB/s,14.672227GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",568,"l2_read_throughput","L2 Throughput (Reads)",3.948171GB/s,296.950572GB/s,184.192589GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=1, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",18,"l2_read_throughput","L2 Throughput (Reads)",1.317230GB/s,9.989016GB/s,9.817297GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasNCHWKernel<float>(int, float const *, float const , tensorflow::BiasNCHWKernel<float>*, int, int)",130,"l2_read_throughput","L2 Throughput (Reads)",266.843203GB/s,298.527763GB/s,291.277784GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",152,"l2_read_throughput","L2 Throughput (Reads)",22.534953GB/s,277.784309GB/s,230.074347GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, int>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",19.143144GB/s,19.682388GB/s,19.490230GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>>(tensorflow::random::PhiloxRandom, tensorflow::random::PhiloxRandomResultElementType*, __int64, tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>>)",20,"l2_read_throughput","L2 Throughput (Reads)",313.536761MB/s,4.063953GB/s,2.135755GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1>*, kernel_grad_params, int, int, float, int, int, int)",8,"l2_read_throughput","L2 Throughput (Reads)",414.895231GB/s,863.828577GB/s,779.047245GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",16.060430GB/s,16.897810GB/s,16.512603GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::BlockReduceKernel<float*, float*, int=256, tensorflow::functor::Sum<float>>(float*, float*, int, float, std::iterator_traits<tensorflow::functor::BlockReduceKernel<float*, float*, int=256, tensorflow::functor::Sum<float>>>::value_type)",10,"l2_read_throughput","L2 Throughput (Reads)",771.055830MB/s,842.781954MB/s,827.388449MB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>>::value_type)",40,"l2_read_throughput","L2 Throughput (Reads)",157.632118MB/s,599.002049MB/s,286.856926MB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_32x128_nt",10,"l2_read_throughput","L2 Throughput (Reads)",224.360880GB/s,239.390167GB/s,234.716456GB/s
"Tesla V100-SXM2-16GB (0)","volta_cgemm_32x64_tn",14,"l2_read_throughput","L2 Throughput (Reads)",166.914099GB/s,282.685548GB/s,271.668939GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)",34,"l2_read_throughput","L2 Throughput (Reads)",381.749694GB/s,535.479245GB/s,512.952458GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",757.886873MB/s,800.286139MB/s,781.166471MB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=1, int=2, int=256, int=16, int=16, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",10,"l2_read_throughput","L2 Throughput (Reads)",353.797641GB/s,377.984531GB/s,375.440657GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",40,"l2_read_throughput","L2 Throughput (Reads)",88.933231GB/s,108.852454GB/s,97.662856GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorReshapingOp<Eigen::IndexList<int> const , Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>> const > const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",15.468772GB/s,16.338890GB/s,16.177119GB/s
"Tesla V100-SXM2-16GB (0)","void cub::DeviceReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int, cub::Sum>(int, cub::Sum, cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, cub::GridEvenShare<cub::Sum>, float)",110,"l2_read_throughput","L2 Throughput (Reads)",258.473525GB/s,815.418548GB/s,723.405256GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=512, int=6, int=8, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=512, int=6, int=8, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",46,"l2_read_throughput","L2 Throughput (Reads)",286.984088GB/s,355.457367GB/s,338.595746GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",2,"l2_read_throughput","L2 Throughput (Reads)",439.759033GB/s,440.752112GB/s,440.255064GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x32_nt",10,"l2_read_throughput","L2 Throughput (Reads)",344.053317GB/s,358.884948GB/s,352.557956GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_pad<int=0, int=1, int=256, int=16, int=16, int=1, float, float, float2>(float2*, float*, int, int3, float*, int, float*, float*, int, int, int, int, int, bool)",20,"l2_read_throughput","L2 Throughput (Reads)",252.085650MB/s,390.288783GB/s,158.392244GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::ColumnReduceKernel<float const *, float*, cub::Sum>(float const *, float*, int, int, cub::Sum, std::iterator_traits<tensorflow::functor::ColumnReduceKernel<float const *, float*, cub::Sum>>::value_type)",26,"l2_read_throughput","L2 Throughput (Reads)",2.315721GB/s,63.329935GB/s,46.188371GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=1, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",28,"l2_read_throughput","L2 Throughput (Reads)",3.694805GB/s,79.595341GB/s,8.040567GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",34,"l2_read_throughput","L2 Throughput (Reads)",343.666420MB/s,3.871955GB/s,2.099818GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_relu_small_nn_v1",8,"l2_read_throughput","L2 Throughput (Reads)",211.602351GB/s,244.146449GB/s,228.599696GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_product_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",40,"l2_read_throughput","L2 Throughput (Reads)",52.992871GB/s,62.875631GB/s,59.127909GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_64x64<float>(float2*, float const *, int, int, int, int, int, int, int, int)",24,"l2_read_throughput","L2 Throughput (Reads)",2.195958GB/s,303.134205GB/s,53.674337GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const *, tensorflow::BiasGradNHWC_SharedAtomics<float>*, int)",11,"l2_read_throughput","L2 Throughput (Reads)",28.698533GB/s,206.683133GB/s,51.696054GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",54,"l2_read_throughput","L2 Throughput (Reads)",284.852805GB/s,317.258000GB/s,291.057426GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>, float const , cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>, float const , cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",20,"l2_read_throughput","L2 Throughput (Reads)",523.631824GB/s,547.477763GB/s,531.538250GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_pad<int=0, int=1, int=128, int=16, int=32, int=1, float, float, float2>(float2*, float*, int, int3, float*, int, float*, float*, int, int, int, int, int, bool)",24,"l2_read_throughput","L2 Throughput (Reads)",677.526847MB/s,328.929325GB/s,92.150061GB/s
"Tesla V100-SXM2-16GB (0)","void im2col4d_kernel<float, int>(im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const *, float*, int)",18,"l2_read_throughput","L2 Throughput (Reads)",50.044103GB/s,114.331724GB/s,84.640244GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=0, int=1, int=256, int=16, int=16, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",20,"l2_read_throughput","L2 Throughput (Reads)",335.687798GB/s,374.476833GB/s,372.481093GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",24,"l2_read_throughput","L2 Throughput (Reads)",310.728540GB/s,359.672314GB/s,343.230817GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=4, int=1, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",34,"l2_read_throughput","L2 Throughput (Reads)",1125.825692GB/s,1159.625386GB/s,1143.125572GB/s
"Tesla V100-SXM2-16GB (0)","compute_gemm_pointers(float2**, float2 const *, int, float2 const *, int, float2 const *, int, int)",26,"l2_read_throughput","L2 Throughput (Reads)",51.347579MB/s,2.273058GB/s,605.312054MB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)",18,"l2_read_throughput","L2 Throughput (Reads)",5.623080GB/s,554.350262GB/s,482.763062GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",24,"l2_read_throughput","L2 Throughput (Reads)",510.680983GB/s,516.681187GB/s,514.266301GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, int>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, int>(Eigen::internal::SumReducer<float>, float, long=1, float, Eigen::internal::SumReducer<float>::CoeffReturnType*)",10,"l2_read_throughput","L2 Throughput (Reads)",750.938975MB/s,793.288001MB/s,768.071980MB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_nn",10,"l2_read_throughput","L2 Throughput (Reads)",465.970992GB/s,545.428287GB/s,503.897149GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<__int64, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<__int64, __int64, Eigen::internal::scalar_max_op<__int64, __int64>>, Eigen::TensorMap<Eigen::Tensor<__int64 const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(__int64, int=1)",1,"l2_read_throughput","L2 Throughput (Reads)",400.703494MB/s,400.703494MB/s,400.703243MB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=0, int=1, int=128, int=8, int=8, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",24,"l2_read_throughput","L2 Throughput (Reads)",368.817059GB/s,379.990566GB/s,378.252628GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_nt",34,"l2_read_throughput","L2 Throughput (Reads)",260.445721GB/s,551.556774GB/s,443.524052GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::cask::generateWinogradTilesKernel<int=0, cudnn::cask::Element<float>, cudnn::cask::Element<float>, cudnn::cask::Element<float>>(cudnn::cask::GenerateWinogradTilesParams)",2,"l2_read_throughput","L2 Throughput (Reads)",2.090724GB/s,4.806826GB/s,3.709939GB/s
"Tesla V100-SXM2-16GB (0)","void cub::DeviceReduceSingleTileKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float*, float*, int, cub::Sum, float>(int, cub::Sum, cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float*, float*)",110,"l2_read_throughput","L2 Throughput (Reads)",263.617290MB/s,2.643754GB/s,1.096975GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_left<float, float, Eigen::internal::scalar_sum_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",20,"l2_read_throughput","L2 Throughput (Reads)",48.249242GB/s,56.450384GB/s,53.965608GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_splitK_xregs_large_nn_v1",16,"l2_read_throughput","L2 Throughput (Reads)",89.532161GB/s,247.091959GB/s,175.436674GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)",34,"l2_read_throughput","L2 Throughput (Reads)",1.950152GB/s,139.210394GB/s,121.270804GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",10,"l2_read_throughput","L2 Throughput (Reads)",451.649228GB/s,511.527216GB/s,480.738034GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=2, int=2, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",38,"l2_read_throughput","L2 Throughput (Reads)",1016.988108GB/s,1177.765851GB/s,1060.680984GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_16x16<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",6,"l2_read_throughput","L2 Throughput (Reads)",229.406278GB/s,628.696105GB/s,572.259359GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_64x32_sliced1x4_tn",10,"l2_read_throughput","L2 Throughput (Reads)",421.623118GB/s,440.229207GB/s,431.539973GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",30,"l2_read_throughput","L2 Throughput (Reads)",243.963197MB/s,866.366104MB/s,478.540796MB/s
"Tesla V100-SXM2-16GB (0)","void transpose_readWrite_alignment_kernel<float2, float2, int=1, bool=0, int=6, int=4, int=4>(cublasTransposeParams<float2>, float2 const *, float2*, float2 const *)",24,"l2_read_throughput","L2 Throughput (Reads)",345.656711GB/s,382.543112GB/s,379.367405GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, int>(Eigen::internal::SumReducer<float>, float, long=1, float, Eigen::internal::SumReducer<float>::CoeffReturnType*)",10,"l2_read_throughput","L2 Throughput (Reads)",2.302577GB/s,2.317642GB/s,2.309348GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_32x32<float, bool=0, unsigned int=1, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*)",8,"l2_read_throughput","L2 Throughput (Reads)",403.005164GB/s,711.189481GB/s,689.409265GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const , float const , Eigen::internal::ComparisonName>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",150,"l2_read_throughput","L2 Throughput (Reads)",85.804489GB/s,515.925500GB/s,504.820912GB/s
