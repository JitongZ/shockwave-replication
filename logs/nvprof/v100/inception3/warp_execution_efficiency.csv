==22904== NVPROF is profiling process 22904, command: python tf_cnn_benchmarks.py --num_gpus=1 --batch_size=64 --num_batches=10 --num_warmup_batches=0 --model=inception3 --data_dir=/home/keshavsanthanam/data/imagenet --allow_growth
2018-12-26 09:50:47.176733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-26 09:50:47.177367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:04.0
totalMemory: 15.75GiB freeMemory: 15.33GiB
2018-12-26 09:50:47.177394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-26 09:50:48.082660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-26 09:50:48.082711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-26 09:50:48.082719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-26 09:50:48.083097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14837 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
W1226 09:50:53.172661 139784277844352 tf_logging.py:125] From /home/keshavsanthanam/dl_scheduling/workloads/tensorflow/image_classification/benchmark_cnn.py:2250: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2018-12-26 09:50:54.080360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-26 09:50:54.080451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-26 09:50:54.080457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-26 09:50:54.080473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-26 09:50:54.081866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14837 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
I1226 09:51:02.624281 139784277844352 tf_logging.py:115] Running local_init_op.
I1226 09:51:33.378787 139784277844352 tf_logging.py:115] Done running local_init_op.
TensorFlow:  1.12
Model:       inception3
Dataset:     imagenet
Mode:        training
SingleSess:  False
Batch size:  64 global
             64 per device
Num batches: 10
Num epochs:  0.00
Devices:     ['/gpu:0']
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
==========
start:2018-12-26 09:50:48.085661
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 0.2 +/- 0.0 (jitter = 0.0)	7.413
10	images/sec: 0.5 +/- 0.0 (jitter = 0.0)	7.372
----------------------------------------------------------------
total images/sec: 0.53
----------------------------------------------------------------
end:2018-12-26 10:11:43.645133
==22904== Profiling application: python tf_cnn_benchmarks.py --num_gpus=1 --batch_size=64 --num_batches=10 --num_warmup_batches=0 --model=inception3 --data_dir=/home/keshavsanthanam/data/imagenet --allow_growth
==22904== Profiling result:
==22904== Metric result:
"Device","Kernel","Invocations","Metric Name","Metric Description","Min","Max","Avg"
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",2955,"warp_execution_efficiency","Warp Execution Efficiency",97.787500%,100.000000%,99.224917%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const , float const >, Eigen::TensorBroadcastingOp<Eigen::array<long, unsigned long=1> const , Eigen::TensorReshapingOp<Eigen::Sizes<> const , Eigen::TensorMap<Eigen::TensorFixedSize<float const , Eigen::Sizes<>, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1900,"warp_execution_efficiency","Warp Execution Efficiency",97.184567%,100.000000%,99.264606%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",90,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void flip_filter<float, float>(float*, float const *, int, int, int, int)",136,"warp_execution_efficiency","Warp Execution Efficiency",3.125000%,100.000000%,49.704667%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::MaxReducer<float>, int>(Eigen::internal::MaxReducer<float>, float, long=1, float, Eigen::internal::MaxReducer<float>::CoeffReturnType*)",10,"warp_execution_efficiency","Warp Execution Efficiency",77.349411%,77.704388%,77.558086%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=4, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, int=4> const , Eigen::DSizes<int, int=4> const , Eigen::TensorMap<Eigen::Tensor<float const , int=4, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=4)",460,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)",12,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1880,"warp_execution_efficiency","Warp Execution Efficiency",97.886394%,100.000000%,98.807876%
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",12,"warp_execution_efficiency","Warp Execution Efficiency",96.279519%,100.000000%,99.379920%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",14,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",20,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void fft1d_c2r_32<float2, float, float, bool=0, bool=1, bool=0, bool=1>(float*, float2 const *, int, int3, int3, int2, int, float, float, float*, float*)",24,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeBOffsetsKernel(cudnn::gemm::ComputeBOffsetsParams)",76,"warp_execution_efficiency","Warp Execution Efficiency",67.000000%,90.375000%,70.075658%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_splitK_small_nn_v1",12,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",212,"warp_execution_efficiency","Warp Execution Efficiency",99.904987%,100.000000%,99.986591%
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=1, int=2, int=128, int=8, int=8, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",12,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeWgradBOffsetsKernel(cudnn::gemm::ComputeBOffsetsParams)",172,"warp_execution_efficiency","Warp Execution Efficiency",58.600000%,94.085100%,69.583716%
"Tesla V100-SXM2-16GB (0)","void scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)",1124,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x128_nn",6,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_splitK_interior_nn_v1",20,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x128_nt",12,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=6, int=5, int=4, int=4, bool=1, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=6, int=5, int=4, int=4, bool=1, bool=1>*, kernel_grad_params, int, int, float, int, int)",24,"warp_execution_efficiency","Warp Execution Efficiency",80.612467%,91.846577%,86.229522%
"Tesla V100-SXM2-16GB (0)","void pointwise_mult_and_sum_complex<float2, int=8, int=4>(float2*, float2*, float2*, int, int, int, int, int, float2)",8,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",90,"warp_execution_efficiency","Warp Execution Efficiency",57.985438%,63.553422%,59.720639%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_relu_interior_nn_v1",12,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_small_nn_v1",12,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasNHWCKernel<float>(int, float const *, float const , tensorflow::BiasNHWCKernel<float>*, int)",10,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(cudnnTensorStruct, float const *, cudnn::detail::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::detail::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",940,"warp_execution_efficiency","Warp Execution Efficiency",98.882596%,99.527943%,99.099141%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1000,"warp_execution_efficiency","Warp Execution Efficiency",97.574421%,100.000000%,99.969135%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_sum_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",10,"warp_execution_efficiency","Warp Execution Efficiency",97.972021%,97.972021%,97.972021%
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, int=1024, int=1024, int=2, bool=0>(unsigned int const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, int=1024, int=1024, int=2, bool=0>*)",10,"warp_execution_efficiency","Warp Execution Efficiency",95.145242%,95.145242%,95.145242%
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)",2,"warp_execution_efficiency","Warp Execution Efficiency",88.061775%,88.061775%,88.061775%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",472,"warp_execution_efficiency","Warp Execution Efficiency",99.982488%,100.000000%,99.997669%
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)",2,"warp_execution_efficiency","Warp Execution Efficiency",98.466846%,98.466846%,98.466846%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1>*, kernel_grad_params, int, int, float, int, int, int)",474,"warp_execution_efficiency","Warp Execution Efficiency",99.261740%,99.990843%,99.685448%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",940,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",270,"warp_execution_efficiency","Warp Execution Efficiency",98.750653%,100.000000%,99.665753%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1880,"warp_execution_efficiency","Warp Execution Efficiency",97.982804%,100.000000%,98.859745%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_splitK_medium_nn_v1",12,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_32x32<float, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*)",284,"warp_execution_efficiency","Warp Execution Efficiency",73.563749%,95.155930%,92.705218%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",2,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_small_nn_v1",26,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_relu_small_nn_v1",26,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","volta_cgemm_32x32_tn",1638,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_clip<int=1, int=2, int=256, int=16, int=16, int=1, float, float, float2>(float*, float2*, int, int3, float2*, int, float2*, float2*, int, int, int, int, int, float, float, bool, int, float, float)",12,"warp_execution_efficiency","Warp Execution Efficiency",97.423160%,99.339122%,98.102611%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorBroadcastingOp<Eigen::array<int, unsigned long=1> const , Eigen::TensorReshapingOp<Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorMap<Eigen::TensorFixedSize<bool const , Eigen::Sizes<>, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",10,"warp_execution_efficiency","Warp Execution Efficiency",91.068262%,91.068262%,91.068262%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",392,"warp_execution_efficiency","Warp Execution Efficiency",99.979273%,100.000000%,99.991116%
"Tesla V100-SXM2-16GB (0)","void fft1d_r2c_32<float, float, float2, bool=0, bool=0>(float2*, float const *, int, int3, int3, int2, int2)",198,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void fft1d_r2c_32<float, float, float2, bool=1, bool=0>(float2*, float const *, int, int3, int3, int2, int2)",62,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::BlockReduceKernel<cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int=256, cub::Sum>(float, float, int, float*, std::iterator_traits<tensorflow::functor::BlockReduceKernel<cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int=256, cub::Sum>>::value_type)",870,"warp_execution_efficiency","Warp Execution Efficiency",96.473673%,99.608430%,98.537383%
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",24,"warp_execution_efficiency","Warp Execution Efficiency",98.151408%,100.000000%,99.117936%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, unsigned long=2> const , Eigen::array<int, unsigned long=2> const , Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>>, Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::GpuDevice>, int>(int, unsigned long=2)",460,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",6,"warp_execution_efficiency","Warp Execution Efficiency",65.412762%,65.412762%,65.412762%
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=1, int=4, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",36,"warp_execution_efficiency","Warp Execution Efficiency",99.997364%,99.999456%,99.998082%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_bw_kernel_avg<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>(cudnnTensorStruct, float const *, float const , cudnn::detail::pooling_bw_kernel_avg<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>, float const , cudnn::detail::pooling_bw_kernel_avg<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",90,"warp_execution_efficiency","Warp Execution Efficiency",41.208022%,86.352656%,80.439757%
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_64x64<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",60,"warp_execution_efficiency","Warp Execution Efficiency",92.524409%,95.541343%,93.502213%
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::ShuffleInTensor3Simple<float, int=2, int=1, int=0, bool=0>(int, float const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::ShuffleInTensor3Simple<float, int=2, int=1, int=0, bool=0>*)",2810,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","volta_gcgemm_32x32_nt",276,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_16x16<float>(float2*, float const *, int, int, int, int, int, int, int, int)",132,"warp_execution_efficiency","Warp Execution Efficiency",81.872736%,88.628159%,86.618792%
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::TruncatedNormalDistribution<tensorflow::random::SingleSampleAdapter<tensorflow::random::PhiloxRandom>, float>>(tensorflow::random::PhiloxRandom, tensorflow::random::PhiloxRandomResultElementType*, __int64, tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::TruncatedNormalDistribution<tensorflow::random::SingleSampleAdapter<tensorflow::random::PhiloxRandom>, float>>)",95,"warp_execution_efficiency","Warp Execution Efficiency",71.489156%,98.021443%,75.706237%
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_clip<int=1, int=2, int=128, int=16, int=32, int=1, float, float, float2>(float*, float2*, int, int3, float2*, int, float2*, float2*, int, int, int, int, int, float, float, bool, int, float, float)",12,"warp_execution_efficiency","Warp Execution Efficiency",85.276459%,99.838623%,90.295888%
"Tesla V100-SXM2-16GB (0)","volta_cgemm_64x32_tn",12,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeWgradSplitKOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",172,"warp_execution_efficiency","Warp Execution Efficiency",51.668432%,76.396792%,56.676521%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_splitK_small_nn_v1",40,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",14,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, int=0, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, int=0, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",50,"warp_execution_efficiency","Warp Execution Efficiency",74.781977%,80.830671%,78.352178%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, unsigned long=2> const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"warp_execution_efficiency","Warp Execution Efficiency",97.285834%,97.285834%,97.285834%
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",388,"warp_execution_efficiency","Warp Execution Efficiency",79.496883%,96.657754%,92.255833%
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=1, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",12,"warp_execution_efficiency","Warp Execution Efficiency",76.742113%,76.742113%,76.742113%
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",104,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=4, int=6, int=3, int=2, int=4, bool=1, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=4, int=6, int=3, int=2, int=4, bool=1, bool=1>*, kernel_grad_params, int, int, float, int, int)",4,"warp_execution_efficiency","Warp Execution Efficiency",92.441239%,95.016046%,93.728643%
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=5, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",2,"warp_execution_efficiency","Warp Execution Efficiency",95.253165%,95.253165%,95.253165%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, int>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_relu_interior_nn_v1",34,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1>*, kernel_grad_params, int, int, float, int, int, int)",234,"warp_execution_efficiency","Warp Execution Efficiency",98.766401%,99.990140%,99.668554%
"Tesla V100-SXM2-16GB (0)","volta_gcgemm_64x32_nt",172,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","volta_sgemm_32x128_nn",10,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"warp_execution_efficiency","Warp Execution Efficiency",99.954655%,99.954655%,99.954655%
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::BlockReduceKernel<float*, float*, int=256, tensorflow::functor::Sum<float>>(float*, float*, int, float, std::iterator_traits<tensorflow::functor::BlockReduceKernel<float*, float*, int=256, tensorflow::functor::Sum<float>>>::value_type)",10,"warp_execution_efficiency","Warp Execution Efficiency",95.254403%,95.254403%,95.254403%
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>>::value_type)",850,"warp_execution_efficiency","Warp Execution Efficiency",65.664557%,65.664557%,65.664557%
"Tesla V100-SXM2-16GB (0)","void pooling_bw_kernel_max_nchw_fully_packed_large<float, float, int=3, cudnnNanPropagation_t=0>(cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, int)",10,"warp_execution_efficiency","Warp Execution Efficiency",94.169521%,94.296120%,94.232298%
"Tesla V100-SXM2-16GB (0)","volta_sgemm_32x128_nt",10,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)",24,"warp_execution_efficiency","Warp Execution Efficiency",76.901721%,96.511256%,88.983899%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",10,"warp_execution_efficiency","Warp Execution Efficiency",94.770244%,94.770244%,94.770244%
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=1, int=2, int=256, int=16, int=16, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",12,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_tn",10,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x32_relu_interior_nn_v1",6,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorReshapingOp<Eigen::IndexList<int> const , Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>> const > const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"warp_execution_efficiency","Warp Execution Efficiency",97.768580%,97.768580%,97.768580%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_interior_nn_v1",14,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cub::DeviceReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int, cub::Sum>(int, cub::Sum, cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, cub::GridEvenShare<cub::Sum>, float)",90,"warp_execution_efficiency","Warp Execution Efficiency",97.898089%,97.899825%,97.898282%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=512, int=6, int=8, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=512, int=6, int=8, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",146,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",10,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_pad<int=0, int=1, int=256, int=16, int=16, int=1, float, float, float2>(float2*, float*, int, int3, float*, int, float*, float*, int, int, int, int, int, bool)",24,"warp_execution_efficiency","Warp Execution Efficiency",99.413035%,99.485755%,99.460961%
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::ColumnReduceKernel<float const *, float*, cub::Sum>(float const *, float*, int, int, cub::Sum, std::iterator_traits<tensorflow::functor::ColumnReduceKernel<float const *, float*, cub::Sum>>::value_type)",1,"warp_execution_efficiency","Warp Execution Efficiency",98.869842%,98.869842%,98.869842%
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)",4,"warp_execution_efficiency","Warp Execution Efficiency",76.297405%,76.297405%,76.297405%
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=1, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",68,"warp_execution_efficiency","Warp Execution Efficiency",74.794550%,82.323883%,77.008264%
"Tesla V100-SXM2-16GB (0)","void pooling_bw_kernel_max_nchw_fully_packed_small<float, float, int=3, cudnnNanPropagation_t=0>(cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor)",30,"warp_execution_efficiency","Warp Execution Efficiency",88.028954%,93.835569%,90.572334%
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",162,"warp_execution_efficiency","Warp Execution Efficiency",79.886364%,99.397713%,88.910652%
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=5, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",2,"warp_execution_efficiency","Warp Execution Efficiency",95.247148%,95.247148%,95.247148%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_relu_small_nn_v1",4,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>(float, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnnTensorStruct, float const *, float, float const , float, cudnnTensorStruct*, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const *, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>*, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const *, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const , cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const , cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>)",30,"warp_execution_efficiency","Warp Execution Efficiency",99.859836%,99.946212%,99.888628%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(float, float, float, float, cudnnTensorStruct, float const *, cudnn::detail::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, float const , cudnn::detail::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::detail::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",910,"warp_execution_efficiency","Warp Execution Efficiency",98.806337%,99.726637%,99.119835%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::ReductionInitKernel<float, int>(float, int, Eigen::internal::ReductionInitKernel<float, int>*)",30,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_64x64<float>(float2*, float const *, int, int, int, int, int, int, int, int)",120,"warp_execution_efficiency","Warp Execution Efficiency",95.719287%,95.959748%,95.881582%
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const *, tensorflow::BiasGradNHWC_SharedAtomics<float>*, int)",10,"warp_execution_efficiency","Warp Execution Efficiency",99.207488%,99.207488%,99.207488%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",196,"warp_execution_efficiency","Warp Execution Efficiency",99.992405%,100.000000%,99.996519%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>, float const , cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>, float const , cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",10,"warp_execution_efficiency","Warp Execution Efficiency",60.021622%,60.434662%,60.115649%
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_pad<int=0, int=1, int=128, int=16, int=32, int=1, float, float, float2>(float2*, float*, int, int3, float*, int, float*, float*, int, int, int, int, int, bool)",24,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x32_relu_small_nn_v1",4,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",18,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void fft1d_r2c_32<float, float, float2, bool=0, bool=1>(float2*, float const *, int, int3, int3, int2, int2)",24,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)",4,"warp_execution_efficiency","Warp Execution Efficiency",67.102401%,67.102401%,67.102401%
"Tesla V100-SXM2-16GB (0)","void im2col4d_kernel<float, int>(im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const *, float*, int)",96,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=0, int=1, int=256, int=16, int=16, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",24,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",12,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=4, int=1, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",56,"warp_execution_efficiency","Warp Execution Efficiency",99.948185%,99.984419%,99.969136%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_interior_nn_v1",24,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","compute_gemm_pointers(float2**, float2 const *, int, float2 const *, int, float2 const *, int, int)",210,"warp_execution_efficiency","Warp Execution Efficiency",3.125000%,3.125000%,3.125000%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1>*, kernel_grad_params, int, int, float, int, int, int)",206,"warp_execution_efficiency","Warp Execution Efficiency",99.679018%,100.000000%,99.920697%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",342,"warp_execution_efficiency","Warp Execution Efficiency",99.795187%,100.000000%,99.955145%
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)",12,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, int>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, int>(Eigen::internal::SumReducer<float>, float, long=1, float, Eigen::internal::SumReducer<float>::CoeffReturnType*)",10,"warp_execution_efficiency","Warp Execution Efficiency",95.514070%,95.514712%,95.514305%
"Tesla V100-SXM2-16GB (0)","void fft1d_c2r_32<float2, float, float, bool=0, bool=1, bool=0, bool=0>(float*, float2 const *, int, int3, int3, int2, int, float, float, float*, float*)",136,"warp_execution_efficiency","Warp Execution Efficiency",76.456391%,100.000000%,86.558608%
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_nn",10,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<__int64, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<__int64, __int64, Eigen::internal::scalar_max_op<__int64, __int64>>, Eigen::TensorMap<Eigen::Tensor<__int64 const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(__int64, int=1)",1,"warp_execution_efficiency","Warp Execution Efficiency",93.166494%,93.166494%,93.166494%
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=0, int=1, int=128, int=8, int=8, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",24,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_nt",14,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cub::DeviceReduceSingleTileKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float*, float*, int, cub::Sum, float>(int, cub::Sum, cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float*, float*)",90,"warp_execution_efficiency","Warp Execution Efficiency",93.694085%,95.788477%,94.739803%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_splitK_xregs_large_nn_v1",4,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)",24,"warp_execution_efficiency","Warp Execution Efficiency",92.651757%,100.000000%,98.775293%
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",38,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",1880,"warp_execution_efficiency","Warp Execution Efficiency",98.741883%,98.741883%,98.741883%
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=2, int=2, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",12,"warp_execution_efficiency","Warp Execution Efficiency",99.996466%,99.996466%,99.996466%
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_16x16<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",66,"warp_execution_efficiency","Warp Execution Efficiency",77.899775%,97.793190%,93.446041%
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_splitK_interior_nn_v1",84,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",110,"warp_execution_efficiency","Warp Execution Efficiency",94.301471%,94.301471%,94.301471%
"Tesla V100-SXM2-16GB (0)","void transpose_readWrite_alignment_kernel<float2, float2, int=1, bool=0, int=6, int=4, int=4>(cublasTransposeParams<float2>, float2 const *, float2*, float2 const *)",228,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, int>(Eigen::internal::SumReducer<float>, float, long=1, float, Eigen::internal::SumReducer<float>::CoeffReturnType*)",10,"warp_execution_efficiency","Warp Execution Efficiency",85.479577%,85.479577%,85.479577%
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_32x32<float, bool=0, unsigned int=1, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*)",82,"warp_execution_efficiency","Warp Execution Efficiency",74.395161%,86.448395%,82.964093%
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const , float const , Eigen::internal::ComparisonName>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",940,"warp_execution_efficiency","Warp Execution Efficiency",100.000000%,100.000000%,100.000000%
