==21991== NVPROF is profiling process 21991, command: python tf_cnn_benchmarks.py --num_gpus=1 --batch_size=64 --num_batches=10 --num_warmup_batches=0 --model=inception3 --data_dir=/home/keshavsanthanam/data/imagenet --allow_growth
2018-12-26 09:40:29.108010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-12-26 09:40:29.108648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:04.0
totalMemory: 15.75GiB freeMemory: 15.33GiB
2018-12-26 09:40:29.108675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-26 09:40:30.052193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-26 09:40:30.052249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-26 09:40:30.052257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-26 09:40:30.052616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14837 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
W1226 09:40:35.133831 140050948686208 tf_logging.py:125] From /home/keshavsanthanam/dl_scheduling/workloads/tensorflow/image_classification/benchmark_cnn.py:2250: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2018-12-26 09:40:36.054884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-26 09:40:36.054975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-26 09:40:36.054989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-26 09:40:36.055003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-26 09:40:36.056040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14837 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)
I1226 09:40:38.972137 140050948686208 tf_logging.py:115] Running local_init_op.
I1226 09:41:10.181875 140050948686208 tf_logging.py:115] Done running local_init_op.
TensorFlow:  1.12
Model:       inception3
Dataset:     imagenet
Mode:        training
SingleSess:  False
Batch size:  64 global
             64 per device
Num batches: 10
Num epochs:  0.00
Devices:     ['/gpu:0']
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
==========
start:2018-12-26 09:40:30.055806
Generating training model
Initializing graph
Running warm up
Done warm up
Step	Img/sec	total_loss
1	images/sec: 0.8 +/- 0.0 (jitter = 0.0)	7.345
10	images/sec: 2.5 +/- 0.2 (jitter = 0.0)	7.415
----------------------------------------------------------------
total images/sec: 2.45
----------------------------------------------------------------
end:2018-12-26 09:45:31.966440
==21991== Profiling application: python tf_cnn_benchmarks.py --num_gpus=1 --batch_size=64 --num_batches=10 --num_warmup_batches=0 --model=inception3 --data_dir=/home/keshavsanthanam/data/imagenet --allow_growth
==21991== Profiling result:
==21991== Metric result:
"Device","Kernel","Invocations","Metric Name","Metric Description","Min","Max","Avg"
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_product_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",2955,"l2_read_throughput","L2 Throughput (Reads)",97.966543MB/s,483.480593GB/s,80.758810GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const , float const >, Eigen::TensorBroadcastingOp<Eigen::array<long, unsigned long=1> const , Eigen::TensorReshapingOp<Eigen::Sizes<> const , Eigen::TensorMap<Eigen::TensorFixedSize<float const , Eigen::Sizes<>, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1900,"l2_read_throughput","L2 Throughput (Reads)",229.717171MB/s,458.965785GB/s,154.199095GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",90,"l2_read_throughput","L2 Throughput (Reads)",593.835916GB/s,621.121094GB/s,613.612110GB/s
"Tesla V100-SXM2-16GB (0)","void flip_filter<float, float>(float*, float const *, int, int, int, int)",136,"l2_read_throughput","L2 Throughput (Reads)",12.230109GB/s,165.880438GB/s,42.634338GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::MaxReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::MaxReducer<float>, int>(Eigen::internal::MaxReducer<float>, float, long=1, float, Eigen::internal::MaxReducer<float>::CoeffReturnType*)",10,"l2_read_throughput","L2 Throughput (Reads)",4.475916GB/s,4.644914GB/s,4.571031GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=4, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<int, int=4> const , Eigen::DSizes<int, int=4> const , Eigen::TensorMap<Eigen::Tensor<float const , int=4, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=4)",460,"l2_read_throughput","L2 Throughput (Reads)",213.722249GB/s,339.791543GB/s,312.379200GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)",12,"l2_read_throughput","L2 Throughput (Reads)",179.553914GB/s,315.707844GB/s,284.381502GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1880,"l2_read_throughput","L2 Throughput (Reads)",127.156575MB/s,1.164153GB/s,521.033421MB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",12,"l2_read_throughput","L2 Throughput (Reads)",181.777376GB/s,462.606837GB/s,443.651597GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",14,"l2_read_throughput","L2 Throughput (Reads)",159.007259GB/s,704.493010GB/s,482.786649GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",20,"l2_read_throughput","L2 Throughput (Reads)",583.284285GB/s,591.650936GB/s,588.058268GB/s
"Tesla V100-SXM2-16GB (0)","void fft1d_c2r_32<float2, float, float, bool=0, bool=1, bool=0, bool=1>(float*, float2 const *, int, int3, int3, int2, int, float, float, float*, float*)",24,"l2_read_throughput","L2 Throughput (Reads)",332.192974GB/s,524.099427GB/s,389.273441GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeBOffsetsKernel(cudnn::gemm::ComputeBOffsetsParams)",76,"l2_read_throughput","L2 Throughput (Reads)",151.077119MB/s,535.396107MB/s,354.639673MB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_splitK_small_nn_v1",12,"l2_read_throughput","L2 Throughput (Reads)",246.929303GB/s,338.188010GB/s,280.314489GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",212,"l2_read_throughput","L2 Throughput (Reads)",419.009510GB/s,755.999400GB/s,595.103047GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=1, int=2, int=128, int=8, int=8, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",12,"l2_read_throughput","L2 Throughput (Reads)",382.861113GB/s,386.628425GB/s,385.199444GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeWgradBOffsetsKernel(cudnn::gemm::ComputeBOffsetsParams)",172,"l2_read_throughput","L2 Throughput (Reads)",137.466568MB/s,740.717916MB/s,316.590026MB/s
"Tesla V100-SXM2-16GB (0)","void scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)",1104,"l2_read_throughput","L2 Throughput (Reads)",5.161981MB/s,2.844767GB/s,74.568781MB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x128_nn",6,"l2_read_throughput","L2 Throughput (Reads)",154.869219GB/s,271.204647GB/s,198.108395GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_splitK_interior_nn_v1",20,"l2_read_throughput","L2 Throughput (Reads)",175.677467GB/s,340.613416GB/s,269.094610GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x128_nt",12,"l2_read_throughput","L2 Throughput (Reads)",43.708004GB/s,278.356007GB/s,101.126150GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=6, int=5, int=4, int=4, bool=1, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=6, int=5, int=4, int=4, bool=1, bool=1>*, kernel_grad_params, int, int, float, int, int)",14,"l2_read_throughput","L2 Throughput (Reads)",385.046748GB/s,612.566770GB/s,605.418743GB/s
"Tesla V100-SXM2-16GB (0)","void pointwise_mult_and_sum_complex<float2, int=8, int=4>(float2*, float2*, float2*, int, int, int, int, int, float2)",8,"l2_read_throughput","L2 Throughput (Reads)",883.950500GB/s,1018.061353GB/s,954.352634GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",90,"l2_read_throughput","L2 Throughput (Reads)",110.526314GB/s,506.188281GB/s,172.146654GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_relu_interior_nn_v1",12,"l2_read_throughput","L2 Throughput (Reads)",185.771883GB/s,332.082117GB/s,242.058522GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_small_nn_v1",12,"l2_read_throughput","L2 Throughput (Reads)",147.769902GB/s,198.786409GB/s,159.558958GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasNHWCKernel<float>(int, float const *, float const , tensorflow::BiasNHWCKernel<float>*, int)",10,"l2_read_throughput","L2 Throughput (Reads)",94.156134GB/s,97.173959GB/s,95.822614GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(cudnnTensorStruct, float const *, cudnn::detail::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::detail::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",940,"l2_read_throughput","L2 Throughput (Reads)",187.492815GB/s,263.264461GB/s,224.619386GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1000,"l2_read_throughput","L2 Throughput (Reads)",1.815688GB/s,508.113744GB/s,269.283641GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<float, float, Eigen::internal::scalar_sum_op<float, float>>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",560.094440MB/s,583.238837MB/s,574.221909MB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, int=1024, int=1024, int=2, bool=0>(unsigned int const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, int=1024, int=1024, int=2, bool=0>*)",10,"l2_read_throughput","L2 Throughput (Reads)",493.196090GB/s,499.947816GB/s,497.552645GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)",2,"l2_read_throughput","L2 Throughput (Reads)",239.943899GB/s,246.576145GB/s,243.210293GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",472,"l2_read_throughput","L2 Throughput (Reads)",483.875707GB/s,860.265548GB/s,566.297907GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)",2,"l2_read_throughput","L2 Throughput (Reads)",179.369460GB/s,184.782349GB/s,182.019352GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1>*, kernel_grad_params, int, int, float, int, int, int)",484,"l2_read_throughput","L2 Throughput (Reads)",709.139086GB/s,898.824447GB/s,751.016048GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",940,"l2_read_throughput","L2 Throughput (Reads)",209.707417GB/s,490.064927GB/s,356.052170GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",270,"l2_read_throughput","L2 Throughput (Reads)",244.298209GB/s,464.438557GB/s,352.207946GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",1880,"l2_read_throughput","L2 Throughput (Reads)",110.251366MB/s,1.136529GB/s,522.728917MB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_splitK_medium_nn_v1",12,"l2_read_throughput","L2 Throughput (Reads)",358.443346GB/s,399.485195GB/s,377.049177GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_32x32<float, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*)",284,"l2_read_throughput","L2 Throughput (Reads)",102.975085GB/s,440.706483GB/s,149.390340GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",2,"l2_read_throughput","L2 Throughput (Reads)",380.665265GB/s,381.389464GB/s,381.027352GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_small_nn_v1",26,"l2_read_throughput","L2 Throughput (Reads)",175.988266GB/s,272.341515GB/s,235.553746GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_relu_small_nn_v1",26,"l2_read_throughput","L2 Throughput (Reads)",174.121486GB/s,280.070935GB/s,232.081493GB/s
"Tesla V100-SXM2-16GB (0)","volta_cgemm_32x32_tn",1638,"l2_read_throughput","L2 Throughput (Reads)",189.452133GB/s,702.622957GB/s,527.388721GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_clip<int=1, int=2, int=256, int=16, int=16, int=1, float, float, float2>(float*, float2*, int, int3, float2*, int, float2*, float2*, int, int, int, int, int, float, float, bool, int, float, float)",12,"l2_read_throughput","L2 Throughput (Reads)",302.469386GB/s,326.299334GB/s,308.710093GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorSelectOp<Eigen::TensorBroadcastingOp<Eigen::array<int, unsigned long=1> const , Eigen::TensorReshapingOp<Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorMap<Eigen::TensorFixedSize<bool const , Eigen::Sizes<>, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",422.432919MB/s,446.400743MB/s,439.849581MB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",402,"l2_read_throughput","L2 Throughput (Reads)",146.988821GB/s,960.339546GB/s,522.471309GB/s
"Tesla V100-SXM2-16GB (0)","void fft1d_r2c_32<float, float, float2, bool=0, bool=0>(float2*, float const *, int, int3, int3, int2, int2)",198,"l2_read_throughput","L2 Throughput (Reads)",2.405100GB/s,262.617401GB/s,118.203004GB/s
"Tesla V100-SXM2-16GB (0)","void fft1d_r2c_32<float, float, float2, bool=1, bool=0>(float2*, float const *, int, int3, int3, int2, int2)",62,"l2_read_throughput","L2 Throughput (Reads)",10.898898GB/s,88.236189GB/s,72.278499GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::BlockReduceKernel<cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int=256, cub::Sum>(float, float, int, float*, std::iterator_traits<tensorflow::functor::BlockReduceKernel<cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int=256, cub::Sum>>::value_type)",870,"l2_read_throughput","L2 Throughput (Reads)",687.532646MB/s,68.487602GB/s,50.690517GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",24,"l2_read_throughput","L2 Throughput (Reads)",169.481946GB/s,395.865879GB/s,369.036276GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorSlicingOp<Eigen::array<int, unsigned long=2> const , Eigen::array<int, unsigned long=2> const , Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>>, Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::GpuDevice>, int>(int, unsigned long=2)",460,"l2_read_throughput","L2 Throughput (Reads)",226.836984GB/s,350.095336GB/s,322.612250GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",6,"l2_read_throughput","L2 Throughput (Reads)",127.087007GB/s,137.236756GB/s,132.124783GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=1, int=4, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",16,"l2_read_throughput","L2 Throughput (Reads)",992.338423GB/s,1134.194404GB/s,1123.161361GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_bw_kernel_avg<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>(cudnnTensorStruct, float const *, float const , cudnn::detail::pooling_bw_kernel_avg<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>, float const , cudnn::detail::pooling_bw_kernel_avg<float, float, cudnn::detail::averpooling_func<float>, int=2, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",90,"l2_read_throughput","L2 Throughput (Reads)",2.487850GB/s,99.739300GB/s,77.211379GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_64x64<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",60,"l2_read_throughput","L2 Throughput (Reads)",320.993095GB/s,638.512441GB/s,510.791470GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::ShuffleInTensor3Simple<float, int=2, int=1, int=0, bool=0>(int, float const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::ShuffleInTensor3Simple<float, int=2, int=1, int=0, bool=0>*)",2810,"l2_read_throughput","L2 Throughput (Reads)",767.893605MB/s,1179.104639GB/s,628.075488GB/s
"Tesla V100-SXM2-16GB (0)","volta_gcgemm_32x32_nt",276,"l2_read_throughput","L2 Throughput (Reads)",434.671912GB/s,907.564288GB/s,804.722479GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_16x16<float>(float2*, float const *, int, int, int, int, int, int, int, int)",132,"l2_read_throughput","L2 Throughput (Reads)",2.591230GB/s,127.734401GB/s,38.764257GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::TruncatedNormalDistribution<tensorflow::random::SingleSampleAdapter<tensorflow::random::PhiloxRandom>, float>>(tensorflow::random::PhiloxRandom, tensorflow::random::PhiloxRandomResultElementType*, __int64, tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::TruncatedNormalDistribution<tensorflow::random::SingleSampleAdapter<tensorflow::random::PhiloxRandom>, float>>)",95,"l2_read_throughput","L2 Throughput (Reads)",343.210225MB/s,33.858064GB/s,17.060871GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_clip<int=1, int=2, int=128, int=16, int=32, int=1, float, float, float2>(float*, float2*, int, int3, float2*, int, float2*, float2*, int, int, int, int, int, float, float, bool, int, float, float)",12,"l2_read_throughput","L2 Throughput (Reads)",300.779326GB/s,340.937210GB/s,319.683100GB/s
"Tesla V100-SXM2-16GB (0)","volta_cgemm_64x32_tn",12,"l2_read_throughput","L2 Throughput (Reads)",361.365539GB/s,541.960408GB/s,478.753758GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeWgradSplitKOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",172,"l2_read_throughput","L2 Throughput (Reads)",405.100595MB/s,3.520826GB/s,1.406305GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_splitK_small_nn_v1",40,"l2_read_throughput","L2 Throughput (Reads)",369.698727GB/s,930.807048GB/s,641.411352GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",4,"l2_read_throughput","L2 Throughput (Reads)",559.668873GB/s,565.009519GB/s,561.709246GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, int=0, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_fw_4d_kernel<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, int=0, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",50,"l2_read_throughput","L2 Throughput (Reads)",141.326584GB/s,721.563859GB/s,525.232637GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float, float>, Eigen::TensorBroadcastingOp<Eigen::array<long, unsigned long=2> const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",44.777791GB/s,48.104141GB/s,47.453352GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",388,"l2_read_throughput","L2 Throughput (Reads)",28.811982GB/s,310.015179GB/s,178.206464GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=1, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",12,"l2_read_throughput","L2 Throughput (Reads)",4.348770GB/s,9.605333GB/s,9.301272GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",124,"l2_read_throughput","L2 Throughput (Reads)",7.853315GB/s,271.547905GB/s,70.315410GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=4, int=6, int=3, int=2, int=4, bool=1, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=4, int=6, int=3, int=2, int=4, bool=1, bool=1>*, kernel_grad_params, int, int, float, int, int)",4,"l2_read_throughput","L2 Throughput (Reads)",1211.476664GB/s,1282.480900GB/s,1251.861077GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=5, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",2,"l2_read_throughput","L2 Throughput (Reads)",12.691071GB/s,12.973564GB/s,12.817397GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentGradGenerator<float, int>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",49.951037GB/s,51.520180GB/s,51.039182GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_relu_interior_nn_v1",34,"l2_read_throughput","L2 Throughput (Reads)",267.162252GB/s,561.902920GB/s,357.852001GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=128, int=6, int=8, int=3, int=3, int=5, bool=1>*, kernel_grad_params, int, int, float, int, int, int)",194,"l2_read_throughput","L2 Throughput (Reads)",719.655277GB/s,800.021151GB/s,770.613979GB/s
"Tesla V100-SXM2-16GB (0)","volta_gcgemm_64x32_nt",172,"l2_read_throughput","L2 Throughput (Reads)",300.893459GB/s,735.858330GB/s,663.148493GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_32x128_nn",10,"l2_read_throughput","L2 Throughput (Reads)",307.408417GB/s,351.711298GB/s,329.026736GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",52.351431GB/s,54.144288GB/s,53.557358GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::BlockReduceKernel<float*, float*, int=256, tensorflow::functor::Sum<float>>(float*, float*, int, float, std::iterator_traits<tensorflow::functor::BlockReduceKernel<float*, float*, int=256, tensorflow::functor::Sum<float>>>::value_type)",10,"l2_read_throughput","L2 Throughput (Reads)",847.710503MB/s,887.138899MB/s,866.320122MB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>(float*, float*, int, int, int, cub::Sum, std::iterator_traits<tensorflow::functor::CleanupSegments<float*, float*, cub::Sum>>::value_type)",850,"l2_read_throughput","L2 Throughput (Reads)",39.819386MB/s,603.993733MB/s,181.612962MB/s
"Tesla V100-SXM2-16GB (0)","void pooling_bw_kernel_max_nchw_fully_packed_large<float, float, int=3, cudnnNanPropagation_t=0>(cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, int)",10,"l2_read_throughput","L2 Throughput (Reads)",187.910636GB/s,188.733150GB/s,188.297457GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_32x128_nt",10,"l2_read_throughput","L2 Throughput (Reads)",563.341182GB/s,581.226906GB/s,572.024499GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)",24,"l2_read_throughput","L2 Throughput (Reads)",339.588343GB/s,449.711190GB/s,356.479745GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, long>(float, int=1)",10,"l2_read_throughput","L2 Throughput (Reads)",743.122844MB/s,800.286139MB/s,777.353762MB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=1, int=2, int=256, int=16, int=16, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",12,"l2_read_throughput","L2 Throughput (Reads)",374.774824GB/s,377.808738GB/s,376.807522GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_tn",10,"l2_read_throughput","L2 Throughput (Reads)",229.064579GB/s,236.028472GB/s,233.738128GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x32_relu_interior_nn_v1",6,"l2_read_throughput","L2 Throughput (Reads)",213.551433GB/s,574.912381GB/s,308.831731GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_difference_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=2, int=1, int>, int=16, Eigen::MakePointer> const , Eigen::TensorBroadcastingOp<Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorReshapingOp<Eigen::IndexList<int> const , Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>> const > const > const > const , Eigen::GpuDevice>, int>(float, int=2)",10,"l2_read_throughput","L2 Throughput (Reads)",49.842389GB/s,53.676418GB/s,52.796477GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_interior_nn_v1",14,"l2_read_throughput","L2 Throughput (Reads)",298.554161GB/s,540.490153GB/s,458.825217GB/s
"Tesla V100-SXM2-16GB (0)","void cub::DeviceReduceKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, cub::TransformInputIterator<float, tensorflow::squareHalf<float>, float*, long>, float*, int, cub::Sum>(int, cub::Sum, cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, cub::GridEvenShare<cub::Sum>, float)",90,"l2_read_throughput","L2 Throughput (Reads)",247.228755GB/s,418.537344GB/s,350.843418GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=512, int=6, int=8, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=512, int=6, int=8, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",146,"l2_read_throughput","L2 Throughput (Reads)",274.094032GB/s,303.581202GB/s,282.265279GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",10,"l2_read_throughput","L2 Throughput (Reads)",410.154783GB/s,432.446594GB/s,422.203995GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_pad<int=0, int=1, int=256, int=16, int=16, int=1, float, float, float2>(float2*, float*, int, int3, float*, int, float*, float*, int, int, int, int, int, bool)",24,"l2_read_throughput","L2 Throughput (Reads)",262.237149MB/s,203.564680GB/s,156.125708GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::functor::ColumnReduceKernel<float const *, float*, cub::Sum>(float const *, float*, int, int, cub::Sum, std::iterator_traits<tensorflow::functor::ColumnReduceKernel<float const *, float*, cub::Sum>>::value_type)",1,"l2_read_throughput","L2 Throughput (Reads)",62.804574GB/s,62.804574GB/s,62.804573GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)",4,"l2_read_throughput","L2 Throughput (Reads)",32.836741GB/s,35.600229GB/s,33.918600GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=1, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",68,"l2_read_throughput","L2 Throughput (Reads)",647.551953MB/s,31.277937GB/s,5.731991GB/s
"Tesla V100-SXM2-16GB (0)","void pooling_bw_kernel_max_nchw_fully_packed_small<float, float, int=3, cudnnNanPropagation_t=0>(cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnTensorStruct, float*, cudnnPoolingStruct, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor)",30,"l2_read_throughput","L2 Throughput (Reads)",124.024019GB/s,340.426031GB/s,219.858559GB/s
"Tesla V100-SXM2-16GB (0)","cudnn::gemm::computeOffsetsKernel(cudnn::gemm::ComputeOffsetsParams)",162,"l2_read_throughput","L2 Throughput (Reads)",126.105694MB/s,3.810602GB/s,1.371575GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_32x32<float, unsigned int=5, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool)",2,"l2_read_throughput","L2 Throughput (Reads)",10.470349GB/s,10.724589GB/s,10.580980GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_relu_small_nn_v1",4,"l2_read_throughput","L2 Throughput (Reads)",174.667302GB/s,191.756190GB/s,183.765604GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>(float, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnnTensorStruct, float const *, float, float const , float, cudnnTensorStruct*, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const *, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>*, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const *, cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const , cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const , cudnn::detail::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>)",30,"l2_read_throughput","L2 Throughput (Reads)",304.014689GB/s,460.440737GB/s,365.863891GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(float, float, float, float, cudnnTensorStruct, float const *, cudnn::detail::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, float const , cudnn::detail::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::detail::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",910,"l2_read_throughput","L2 Throughput (Reads)",269.148133GB/s,402.388119GB/s,350.388201GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::ReductionInitKernel<float, int>(float, int, Eigen::internal::ReductionInitKernel<float, int>*)",30,"l2_read_throughput","L2 Throughput (Reads)",158.945719MB/s,440.157376MB/s,259.150325MB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_r2c_64x64<float>(float2*, float const *, int, int, int, int, int, int, int, int)",120,"l2_read_throughput","L2 Throughput (Reads)",1.038956GB/s,158.805786GB/s,94.385394GB/s
"Tesla V100-SXM2-16GB (0)","void tensorflow::BiasGradNHWC_SharedAtomics<float>(int, float const *, tensorflow::BiasGradNHWC_SharedAtomics<float>*, int)",10,"l2_read_throughput","L2 Throughput (Reads)",86.428840GB/s,92.156052GB/s,90.306402GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",196,"l2_read_throughput","L2 Throughput (Reads)",202.803664GB/s,383.189874GB/s,291.355307GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>(cudnnTensorStruct, float const *, cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>, float const , cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>, float const , cudnn::detail::pooling_bw_kernel_max<float, float, cudnn::detail::maxpooling_func<float, cudnnNanPropagation_t=0>, bool=0>, cudnnTensorStruct*, cudnnPoolingStruct, float, cudnnPoolingStruct, int, cudnn::reduced_divisor, float)",10,"l2_read_throughput","L2 Throughput (Reads)",622.628361GB/s,634.371977GB/s,628.651985GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::regular_fft_pad<int=0, int=1, int=128, int=16, int=32, int=1, float, float, float2>(float2*, float*, int, int3, float*, int, float*, float*, int, int, int, int, int, bool)",24,"l2_read_throughput","L2 Throughput (Reads)",409.572109MB/s,189.301515GB/s,110.371570GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x32_relu_small_nn_v1",4,"l2_read_throughput","L2 Throughput (Reads)",173.960952GB/s,189.948675GB/s,184.117275GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",18,"l2_read_throughput","L2 Throughput (Reads)",429.208123GB/s,935.353137GB/s,780.084140GB/s
"Tesla V100-SXM2-16GB (0)","void fft1d_r2c_32<float, float, float2, bool=0, bool=1>(float2*, float const *, int, int3, int3, int2, int2)",24,"l2_read_throughput","L2 Throughput (Reads)",96.562321GB/s,206.272400GB/s,181.294691GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput9x9_5x5<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)",4,"l2_read_throughput","L2 Throughput (Reads)",801.227125GB/s,864.266325GB/s,832.354633GB/s
"Tesla V100-SXM2-16GB (0)","void im2col4d_kernel<float, int>(im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const *, float*, int)",86,"l2_read_throughput","L2 Throughput (Reads)",26.110358GB/s,311.981667GB/s,123.619550GB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=0, int=1, int=256, int=16, int=16, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",24,"l2_read_throughput","L2 Throughput (Reads)",369.338493GB/s,375.075326GB/s,373.601845GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>(int, int, int, float const *, int, float*, cudnn::detail::implicit_convolve_sgemm<float, float, int=1024, int=6, int=7, int=3, int=3, int=5, int=1, bool=1, bool=0, bool=1>*, kernel_conv_params, int, float, float, int, float, float, int, int)",12,"l2_read_throughput","L2 Throughput (Reads)",317.459769GB/s,331.232991GB/s,326.222840GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=4, int=1, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",96,"l2_read_throughput","L2 Throughput (Reads)",426.511128GB/s,927.233429GB/s,761.807531GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_interior_nn_v1",24,"l2_read_throughput","L2 Throughput (Reads)",160.695150GB/s,366.135442GB/s,310.949832GB/s
"Tesla V100-SXM2-16GB (0)","compute_gemm_pointers(float2**, float2 const *, int, float2 const *, int, float2 const *, int, int)",210,"l2_read_throughput","L2 Throughput (Reads)",51.146778MB/s,2.253957GB/s,893.772446MB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=1>*, kernel_grad_params, int, int, float, int, int, int)",226,"l2_read_throughput","L2 Throughput (Reads)",912.425685GB/s,1068.766452GB/s,1002.206074GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1, int=512>(int, int, int, float const *, int, cudnn::detail::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=1, int=512>*, float const , kernel_grad_params, int, float, int, int, int, int)",342,"l2_read_throughput","L2 Throughput (Reads)",482.067464GB/s,911.982019GB/s,693.646924GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)",12,"l2_read_throughput","L2 Throughput (Reads)",21.730860GB/s,527.095899GB/s,358.619693GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorGeneratorOp<tensorflow::generator::SparseXentLossGenerator<float, int>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, int>(Eigen::internal::SumReducer<float>, float, long=1, float, Eigen::internal::SumReducer<float>::CoeffReturnType*)",10,"l2_read_throughput","L2 Throughput (Reads)",1.408341GB/s,1.482148GB/s,1.443101GB/s
"Tesla V100-SXM2-16GB (0)","void fft1d_c2r_32<float2, float, float, bool=0, bool=1, bool=0, bool=0>(float*, float2 const *, int, int3, int3, int2, int, float, float, float*, float*)",136,"l2_read_throughput","L2 Throughput (Reads)",126.950460GB/s,597.019567GB/s,355.610364GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_nn",10,"l2_read_throughput","L2 Throughput (Reads)",228.302830GB/s,491.753564GB/s,411.248726GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<__int64, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_right<__int64, __int64, Eigen::internal::scalar_max_op<__int64, __int64>>, Eigen::TensorMap<Eigen::Tensor<__int64 const , int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(__int64, int=1)",1,"l2_read_throughput","L2 Throughput (Reads)",480.477136MB/s,480.477136MB/s,480.476909MB/s
"Tesla V100-SXM2-16GB (0)","void DSE::vector_fft<int=0, int=1, int=128, int=8, int=8, int=1, float, float, float2>(float2*, float2, int, int3, float2*)",24,"l2_read_throughput","L2 Throughput (Reads)",376.973216GB/s,380.161759GB/s,379.111081GB/s
"Tesla V100-SXM2-16GB (0)","volta_sgemm_128x64_nt",14,"l2_read_throughput","L2 Throughput (Reads)",274.979536GB/s,499.707950GB/s,401.974510GB/s
"Tesla V100-SXM2-16GB (0)","void cub::DeviceReduceSingleTileKernel<cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float*, float*, int, cub::Sum, float>(int, cub::Sum, cub::DeviceReducePolicy<float, int, cub::Sum>::Policy600, float*, float*)",90,"l2_read_throughput","L2 Throughput (Reads)",257.961085MB/s,1.555922GB/s,586.588333MB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x128_stridedB_splitK_xregs_large_nn_v1",4,"l2_read_throughput","L2 Throughput (Reads)",137.706667GB/s,137.736734GB/s,137.725508GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)",24,"l2_read_throughput","L2 Throughput (Reads)",6.741001GB/s,134.441833GB/s,91.479036GB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::explicit_convolve_sgemm<float, int, int=1024, int=6, int=7, int=3, int=3, int=5, int=0, bool=1>*, kernel_conv_params, int, int, float, float, int, float const *, float const *)",38,"l2_read_throughput","L2 Throughput (Reads)",127.855730GB/s,453.994728GB/s,361.544347GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, int>, int=16, Eigen::MakePointer> const > const > const , Eigen::GpuDevice>, int>(float, int=1)",1880,"l2_read_throughput","L2 Throughput (Reads)",37.035895MB/s,499.119267MB/s,175.021269MB/s
"Tesla V100-SXM2-16GB (0)","void cudnn::winograd::winograd3x3Kernel<float, float, int=2, int=2, int=8, bool=0>(cudnn::maxwell::winograd::KernelParams)",12,"l2_read_throughput","L2 Throughput (Reads)",414.124576GB/s,420.981107GB/s,417.881742GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_16x16<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",66,"l2_read_throughput","L2 Throughput (Reads)",327.013398GB/s,710.403817GB/s,640.333537GB/s
"Tesla V100-SXM2-16GB (0)","volta_scudnn_128x64_stridedB_splitK_interior_nn_v1",84,"l2_read_throughput","L2 Throughput (Reads)",111.464234GB/s,995.265416GB/s,443.905887GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float, float>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_sum_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const , Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",110,"l2_read_throughput","L2 Throughput (Reads)",242.086556MB/s,860.307600MB/s,319.553402MB/s
"Tesla V100-SXM2-16GB (0)","void transpose_readWrite_alignment_kernel<float2, float2, int=1, bool=0, int=6, int=4, int=4>(cublasTransposeParams<float2>, float2 const *, float2*, float2 const *)",228,"l2_read_throughput","L2 Throughput (Reads)",354.387574GB/s,382.488700GB/s,374.769693GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::InnerReductionKernel<int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::SumReducer<float>, Eigen::IndexList<Eigen::type2index<long=1>> const , Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_exp_op<float>, Eigen::TensorMap<Eigen::Tensor<float, int=2, int=1, int>, int=16, Eigen::MakePointer> const > const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::SumReducer<float>, int>(Eigen::internal::SumReducer<float>, float, long=1, float, Eigen::internal::SumReducer<float>::CoeffReturnType*)",10,"l2_read_throughput","L2 Throughput (Reads)",4.844842GB/s,4.884905GB/s,4.865077GB/s
"Tesla V100-SXM2-16GB (0)","void fft2d_c2r_32x32<float, bool=0, unsigned int=1, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*)",82,"l2_read_throughput","L2 Throughput (Reads)",373.729787GB/s,707.163357GB/s,552.307343GB/s
"Tesla V100-SXM2-16GB (0)","void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, int=1, int=1, long>, int=16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_product_op<float const , float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorConversionOp<float, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_cmp_op<float const , float const , Eigen::internal::ComparisonName>, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const , Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const >, Eigen::TensorMap<Eigen::Tensor<float const , int=1, int=1, long>, int=16, Eigen::MakePointer> const > const > const > const > const > const , Eigen::GpuDevice>, long>(float, int=1)",940,"l2_read_throughput","L2 Throughput (Reads)",351.033677GB/s,517.123159GB/s,491.097811GB/s
