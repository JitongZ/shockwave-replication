\documentclass{article}
\usepackage{amsmath}
\title{Gavel Workflow}

\date{\today}
\begin{document}

\maketitle

\section{Policy}

\paragraph{Goal.} Compute the optimal assignment of resources to active applications,
while optimizing a given user-provided metric.

\paragraph{Inputs.}

\begin{itemize}
\item $\text{throughput}_{ij}$: Estimate of throughput of application
$i$ on worker type $j$.

\item $\text{scale}_i$: Number of GPUs to use for application $i$.

\item $\text{num\_workers}_j$: Number of GPUs of type $j$.

\end{itemize}

\paragraph{Outputs.} $\text{allocation}_{ij}$: Fraction of wall-clock time spent
running application $i$ on worker type $j$.


\section{Scheduler}

\paragraph{Goal.} Schedule DL training iterations on the available workers (of
possibly different types), such that for each application, the fraction of time
spent on each worker type is approximately equal to $\text{allocation}_{ij}$.

\paragraph{Assumptions.} Scheduling decisions are made in \emph{rounds}. That is,
the scheduler tries to place work on all available workers for a specific time
quantum (this time period is configurable; could be, for example, 30 minutes).

The first step to scheduling then is to figure out which applications will run
in a given round since the number of active, \emph{schedulable} applications
might far exceed the total number of GPUs available.

\paragraph{State.} $\text{time\_run\_so\_far}_{ij}$: Time spent by an
application $i$ on each worker type $j$. Updated as applications run on different
worker types.

$\text{fraction\_of\_time\_run\_so\_far}_{ij}$ (derived): Fraction of time spent
by each application $i$ on each worker type $j$. Can be computed from $\text{time\_run\_so\_far}_{ij}$.

$\text{priority}_{ij}$ (derived): Computed using,
$$\text{priority}_{ij} = \dfrac{\text{fraction\_of\_time\_run\_so\_far}_{ij}}{\text{allocation}_{ij}}$$

\paragraph{Algorithm.} Now, to move the $\text{fraction\_of\_time\_run\_so\_far}_{ij}$
distribution towards the desired $\text{allocation}_{ij}$ in the current round,
we want to give the applications with lowest priority for each worker type $j$
GPU time.

For simplicity, assume that there is only one worker type, and that each server
only has one GPU (we will discuss how to relax these assumptions a little later).
Then we can structure the problem of determining which of the active applications
to run in the current round using a knapsack-like algorithm.

Let us assume that the total number of active applications is $n$. Let these
$n$ applications have priorities $p_{1j}, p_{2j}, \ldots, p_{nj}$. Let these $n$ applications
have scale requirements $s_1, s_2, \ldots, s_n$. Let the total number of GPUs
available be $m$.

At a high level, we are trying to find the subset of applications among $\{1, 2, \ldots, n\}$
with lowest priority sum ($\sum p_i$) that also fits in the given machine budget
($\sum s_i \leq m$).

Let $A[i][j]$ be the sum of priorities of the optimal subset of applications with
IDs $\leq i$ to run in this round using $j$ GPUs. Then $A[i][j]$ can be
computed using Dynamic Programming,

$$A[i][j] = \min(A[i-1][j], A[i-1][j-s_i] + p_i)$$

since the optimal subset with applications $\leq i$
on $j$ GPUs either contains application $i$ or doesn't.

This has time complexity $O(nm)$.

Now, for GPUs of different types, one can either solve multiple DP problems,
progressively from the fastest GPUs down (this corresponds to first determining
what applications to run on the fastest GPU type, and then progressively to the slower
GPU types). This would have time complexity $O(n(m_1 + m_2 + \ldots + m_k))$, where
$k$ is the total number of GPU types, but is approximate. Note that this is an
approximate solution (since applications that are placed on the fastest GPU
types might actually be better fits on slower GPU types, but the order in which
we solve DP problems precludes this).

Alternatively, one can optimize this directly. Assume 3 different types of GPUs.
We can create a new DP problem $A[i][j][k][l]$ representing the sum of priorities
of the optimal subset of applications $\leq i$ using $j$ GPUs of type 1, $k$
GPUs of type 2, and $l$ GPUs of type 3.

Then, $A[i][j][k][l]$ can be computed as,

$$A[i][j][k][l] = \min(A[i-1][j][k][l], A[i-1][j-s_i][k][l] + p_{i1}, A[i-1][j][k-s_i][l] + p_{i2}, A[i-1][j][k][l-s_i] + p_{i3})$$


This would have time complexity $O(nm_1m_2\ldots m_k)$. This should produce an
optimal solution, but is more computationally expensive.


Now, given the set of applications to run on different worker types in a given
round, we need to figure out how to \emph{place} these applications on the
different worker types. This is trivial when each server only has a single
GPU -- each application can be placed on any GPU, and since the DP problem
above was explicitly solved keeping capacity constraints in mind, we are done.

However, servers can also contain many GPUs, in which case we want to keep
an allocation on the same server as much as possible (to make use of faster
intra-server interconnects compared to much slower inter-server interconnects).

In this case, the GPU assignment problem from above becomes much more interesting:
how do we assign GPUs of a specific type to applications while minimizing
fragmentation of applications? In addition, applications might have different
affinities to being placed on the same server versus different servers (for example,
if distributed training of a certain model involves very little inter-GPU
communication, then it doesn't really make a difference whether model training
is distributed within a server or across servers).

\paragraph{Open Questions.}

\begin{itemize}
\item Given the subset of active applications to run in the next round, how do we
place applications on multi-GPU servers while minimizing fragmentation (or multi-
server communication)? (minimizing fragmentation is akin to maximizing locality)

\textbf{Potential Solution.} Could try to greedily place applications within the
same server? So first place all applications that use an integral multiple of
the number of GPUs on a single server (so if we have 8-GPU servers, first place
applications with scale factors of 8, 16, 32, and so on). Can then use some
greedy heuristics to place the fractional ones. Could also just order applications
in decreasing order of scale factor, and greedily place on a minimal number of
servers until no longer possible. \textit{Anything smarter?}

\item How do we mathematically formulate minimizing movement of applications?
That is, can we make our algorithm prefer allocations / placements that don't
move applications off of GPUs if not needed (effectively give some applications
large time quanta)?

\textbf{Potential Solution.} Can keep track of the assignment in the previous round. Then, if
the same application is placed on the same GPU type, can reuse the assignment from
the previous round (and can perform the assignment for other applications on top
of this existing assignment).

\item Is the assignment problem from above NP-complete? (seems similar to the
standard bin packing problem) Can we prove the approximation factor of one of
the greedy algorithms described above if it is?

\item Different applications might have different affinities to being trained
within or across multi-GPU servers. How can we incorporate these affinities into
a potential assignment / placement algorithm?

\item Is there an easier solution which doesn't involve rounds? Strawperson
solutions to schedule multi-GPU applications seem to involve either 1)
waiting for the required number of workers to finish their current applications
(causing other workers to wait), 2) sending interrupts to running applications
to wrap up execution (but how to select which applications to send interrupts to?).
\textit{But perhaps something smarter?}

\end{itemize}

\end{document}
