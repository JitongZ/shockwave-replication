{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of simulation of different fairness policies\n",
    "\n",
    "These experiments use accumulated deficits to try to ensure that applications always receive their computed allocation of GPU time, even in the event of new jobs coming in and old jobs finishing, by keeping track of the difference between the GPU time the application should have received, and the GPU time the application actually received. Allocation of jobs to GPUs is performed in a round-based fashion, with GPUs instructed to run jobs for a fixed interval of time on all GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for plotting.\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from pylab import *\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "rc('text',\n",
    "   usetex=True)\n",
    "sns.set_style('ticks')\n",
    "font = {\n",
    "    'font.family':'Times New Roman',\n",
    "    'font.weight': 200,\n",
    "    'font.size': 10,\n",
    "}\n",
    "sns.set_style(font)\n",
    "flatui = ['#002A5E', '#FD151B', '#8EBA42', '#348ABD', '#988ED5', '#BDB76B', '#8EBA42', '#FFB5B8']\n",
    "sns.set_palette(flatui)\n",
    "paper_rc = {\n",
    "    'lines.linewidth': 3,\n",
    "    'lines.markersize': 10,\n",
    "    'mathtext.fontset': 'custom',\n",
    "    'mathtext.rm': 'Times New Roman',\n",
    "    'mathtext.bf': 'Times New Roman:bold',\n",
    "}\n",
    "sns.set_context(\"paper\", font_scale=2,  rc=paper_rc)\n",
    "current_palette = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other imports.\n",
    "import os\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_FROM_PICKLED_DATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_f = None\n",
    "writing_f = None\n",
    "if LOAD_FROM_PICKLED_DATA:\n",
    "    reading_f = open(\"throughput_estimation/data.pickle\", 'rb')\n",
    "else:\n",
    "    writing_f = open(\"throughput_estimation/data.pickle\", 'wb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get logfile paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logfile_paths_helper(directory_name):\n",
    "    logfile_paths = []\n",
    "    for root, _, file_names in os.walk(directory_name):\n",
    "        if len(file_names) > 0:\n",
    "            logfile_paths.extend(\n",
    "                [os.path.join(root, file_name)\n",
    "                 for file_name in file_names])\n",
    "    return logfile_paths\n",
    "\n",
    "def get_logfile_paths(directory_name):\n",
    "    logfile_paths = []\n",
    "    for logfile_path in get_logfile_paths_helper(directory_name):\n",
    "        m = re.match(\n",
    "            r'.*v100=(\\d+)\\.p100=(\\d+)\\.k80=(\\d+)/(.*)/'\n",
    "             'profiling_percentage=(\\d+\\.\\d+)/'\n",
    "             'num_reference_models=(\\d+)/'\n",
    "             'seed=(\\d+)/lambda=(\\d+\\.\\d+)\\.log', logfile_path)\n",
    "        if m is None: continue\n",
    "        v100s = int(m.group(1))\n",
    "        p100s = int(m.group(2))\n",
    "        k80s = int(m.group(3))\n",
    "        policy = m.group(4)\n",
    "        profiling_percentage = float(m.group(5))\n",
    "        num_reference_models = int(m.group(6))\n",
    "        seed = int(m.group(7))\n",
    "        l = float(m.group(8))\n",
    "        logfile_paths.append((v100s, p100s, k80s, policy,\n",
    "                              profiling_percentage,\n",
    "                              num_reference_models,\n",
    "                              seed,\n",
    "                              l, logfile_path))\n",
    "    return logfile_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_completion_algos = [\"PMF\"]\n",
    "all_seeds = set([0, 1, 2])\n",
    "all_policies = ['max_min_fairness_perf', 'max_min_fairness_packed']\n",
    "logfile_paths = sorted(get_logfile_paths(\n",
    "    \"/lfs/1/keshav2/gpusched/scheduler/logs/throughput_estimation\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(logfile_paths, v100s, p100s, k80s, policy,\n",
    "          profiling_percentage, num_reference_models,\n",
    "          seed=None):\n",
    "    if seed is None:\n",
    "        return sorted([(x[7], x[8], x[6]) for x in logfile_paths\n",
    "                       if x[0] == v100s and x[1] == p100s and\n",
    "                       x[2] == k80s and x[3] == policy and\n",
    "                       x[4] == profiling_percentage and\n",
    "                       x[5] == num_reference_models])\n",
    "    else:\n",
    "        return sorted([(x[7], x[8]) for x in logfile_paths\n",
    "                       if x[0] == v100s and x[1] == p100s and\n",
    "                       x[2] == k80s and x[3] == policy and\n",
    "                       x[7] == seed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_input_job_rate_vs_average_jct(average_jcts, output_filename=None):\n",
    "    data = {\"input_job_rate\": [], 'average_jct': [], \"seed\": [],\n",
    "            \"label\": []}\n",
    "    \n",
    "    policies = sorted(average_jcts.keys())\n",
    "    for i, policy in enumerate(policies):\n",
    "        for lam in average_jcts[policy]:\n",
    "            input_job_rate = 3600.0 / lam\n",
    "            for seed in average_jcts[policy][lam]:\n",
    "                average_jct = average_jcts[policy][lam][seed]\n",
    "                if average_jct:\n",
    "                    data[\"input_job_rate\"].append(input_job_rate)\n",
    "                    data[\"average_jct\"].append(average_jct)\n",
    "                    data[\"seed\"].append(seed)\n",
    "                    if 'packed' in policy:\n",
    "                        label = 'LAS+perf+packed'\n",
    "                    else:\n",
    "                        label = 'LAS+perf'\n",
    "                    if 'estimated' in policy:\n",
    "                        label += ' [ET]'\n",
    "                    data[\"label\"].append(label)\n",
    "    plt.figure(figsize=(8, 3.5))\n",
    "    ax = plt.subplot2grid((1, 1), (0, 0), colspan=1)\n",
    "    sns.lineplot(x='input_job_rate', y='average_jct', style='label',\n",
    "                 hue='label',\n",
    "                 data=data, ci='sd',\n",
    "                 markers=True)\n",
    "    ax.set_xlabel(\"Input job rate (jobs/hr)\")\n",
    "    ax.set_ylabel(\"Average JCT (hours)\")\n",
    "    plt.ylim(0, 300)\n",
    "    sns.despine()\n",
    "    plt.legend()  \n",
    "    if output_filename is not None:\n",
    "        with PdfPages(output_filename) as pdf:\n",
    "            pdf.savefig(bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot average JCT versus input job rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_jct(logfile_path, min_job_id=None,\n",
    "                   max_job_id=None):\n",
    "    job_completion_times = []\n",
    "    with open(logfile_path, 'rb') as f:\n",
    "        f.seek(-8192, os.SEEK_END)\n",
    "        text = f.read().decode('utf-8')\n",
    "        lines = text.split('\\n')\n",
    "        for line in lines[-5:]:\n",
    "            m = re.match(r'Average job completion time: (\\d+\\.\\d+) seconds', line)\n",
    "            if m is not None:\n",
    "                return float(m.group(1)) / 3600\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric(v100s, p100s, k80s, policies,\n",
    "                   profiling_percentage, num_reference_models,\n",
    "                   seeds):\n",
    "    data = {}\n",
    "    policies_ = []\n",
    "    if reading_f is not None:\n",
    "        data = pickle.load(reading_f)\n",
    "    else:\n",
    "        for policy in policies:\n",
    "            policies_.append(policy)\n",
    "            if 'packed' in policy:\n",
    "                policies_.append(policy + '_estimated')\n",
    "        for i, policy in enumerate(policies_):\n",
    "            if '_estimated' in policy:\n",
    "                profiling_percentage_ = profiling_percentage\n",
    "                policy_ = policy.split('_estimated')[0]\n",
    "            else:\n",
    "                profiling_percentage_ = 0.0\n",
    "                policy_ = policy\n",
    "            data[policy] = {}\n",
    "            relevant_logfile_paths = list(reversed(prune(\n",
    "                logfile_paths, v100s, p100s, k80s, policy_,\n",
    "                profiling_percentage_, num_reference_models)))\n",
    "            for logfile_path in relevant_logfile_paths:\n",
    "                lam, path, seed = logfile_path\n",
    "                if seed not in all_seeds:\n",
    "                    continue\n",
    "                if lam not in data[policy]:\n",
    "                    data[policy][lam] = {}\n",
    "                average_jct = get_average_jct(path, min_job_id=4000, max_job_id=5000)\n",
    "                if average_jct is not None:\n",
    "                    data[policy][lam][seed] = average_jct\n",
    "        pickle.dump(data, writing_f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "profiling_percentage = 1.0/64\n",
    "print(\"V100s=64, P100s=0, K80s=0; Jobs 4000-5000\")\n",
    "print(\"profiling_percentage=%f\" % profiling_percentage)\n",
    "average_jcts = compute_metric(v100s=64, p100s=0, k80s=0,\n",
    "                              policies=all_policies,\n",
    "                              profiling_percentage=profiling_percentage,\n",
    "                              num_reference_models=16,\n",
    "                              seeds=all_seeds)\n",
    "plot_input_job_rate_vs_average_jct(average_jcts,\n",
    "                                   output_filename='throughput_estimation/profiling_percentage=0.015625_v100=64_p100=0_k80=0.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiling_percentage = 2.0/64\n",
    "print(\"V100s=64, P100s=0, K80s=0; Jobs 4000-5000\")\n",
    "print(\"profiling_percentage=%f\" % profiling_percentage)\n",
    "average_jcts = compute_metric(v100s=64, p100s=0, k80s=0,\n",
    "                              policies=all_policies,\n",
    "                              profiling_percentage=profiling_percentage,\n",
    "                              num_reference_models=16,\n",
    "                              seeds=all_seeds)\n",
    "plot_input_job_rate_vs_average_jct(average_jcts,\n",
    "                                   output_filename='throughput_estimation/profiling_percentage=0.03125_v100=64_p100=0_k80=0.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiling_percentage = 4.0/64\n",
    "print(\"V100s=64, P100s=0, K80s=0; Jobs 4000-5000\")\n",
    "print(\"profiling_percentage=%f\" % profiling_percentage)\n",
    "average_jcts = compute_metric(v100s=64, p100s=0, k80s=0,\n",
    "                              policies=all_policies,\n",
    "                              profiling_percentage=profiling_percentage,\n",
    "                              num_reference_models=16,\n",
    "                              seeds=all_seeds)\n",
    "plot_input_job_rate_vs_average_jct(average_jcts,\n",
    "                                   output_filename='throughput_estimation/profiling_percentage=0.0625_v100=64_p100=0_k80=0.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiling_percentage = 1.0/64\n",
    "print(\"V100s=36, P100s=36, K80s=36; Jobs 4000-5000\")\n",
    "print(\"profiling_percentage=%f\" % profiling_percentage)\n",
    "average_jcts = compute_metric(v100s=36, p100s=36, k80s=36,\n",
    "                              policies=all_policies,\n",
    "                              profiling_percentage=profiling_percentage,\n",
    "                              num_reference_models=16,\n",
    "                              seeds=all_seeds)\n",
    "plot_input_job_rate_vs_average_jct(average_jcts,\n",
    "                                   output_filename='throughput_estimation/profiling_percentage=0.015625_v100=36_p100=36_k80=36.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiling_percentage = 2.0/64\n",
    "print(\"V100s=36, P100s=36, K80s=36; Jobs 4000-5000\")\n",
    "print(\"profiling_percentage=%f\" % profiling_percentage)\n",
    "average_jcts = compute_metric(v100s=36, p100s=36, k80s=36,\n",
    "                              policies=all_policies,\n",
    "                              profiling_percentage=profiling_percentage,\n",
    "                              num_reference_models=16,\n",
    "                              seeds=all_seeds)\n",
    "plot_input_job_rate_vs_average_jct(average_jcts,\n",
    "                                   output_filename='throughput_estimation/profiling_percentage=0.03125_v100=36_p100=36_k80=36.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiling_percentage = 4.0/64\n",
    "print(\"V100s=36, P100s=36, K80s=36; Jobs 4000-5000\")\n",
    "print(\"profiling_percentage=%f\" % profiling_percentage)\n",
    "average_jcts = compute_metric(v100s=36, p100s=36, k80s=36,\n",
    "                              policies=all_policies,\n",
    "                              profiling_percentage=profiling_percentage,\n",
    "                              num_reference_models=16,\n",
    "                              seeds=all_seeds)\n",
    "plot_input_job_rate_vs_average_jct(average_jcts,\n",
    "                                   output_filename='throughput_estimation/profiling_percentage=0.0625_v100=36_p100=36_k80=36.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reading_f is not None:\n",
    "    reading_f.close()\n",
    "if writing_f is not None:\n",
    "    writing_f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
